{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:44:51.714094600Z",
     "start_time": "2024-07-01T15:44:49.891837500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from algorithm import (\n",
    "                        NoRegularizationTrainer,\n",
    "                        GradientTrainer,\n",
    "                        EGTrainer,\n",
    "                        CSVDataLoader,\n",
    "                        MultiTaskModel,\n",
    "                        MultiTaskDataset,\n",
    "                        mlt_train_test_split,\n",
    "                        # true_values_from_data_loader,\n",
    "                        unique_value_counts,\n",
    "                        Cindex,\n",
    "                        brier_score,\n",
    "                        )\n",
    "import easydict\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b00ac7b2dbe00c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10f19944d16e58a6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCBP.Name                       0\n",
      "Gender                          0\n",
      "Age                             0\n",
      "Raca.Color                    493\n",
      "State.Civil                  6538\n",
      "Code.Profession              1060\n",
      "Name.Occupation              1060\n",
      "Status.Address                  0\n",
      "City.Address                    0\n",
      "Description.of.Topography       0\n",
      "Topography.Code                 0\n",
      "Morphology.Description          0\n",
      "Code.of.Morphology              0\n",
      "Description.of.Disease          0\n",
      "Illness.Code                    0\n",
      "Indicator.of.Rare.Case          0\n",
      "Diagnostic.means               40\n",
      "Extension                       0\n",
      "Survival_Time                   0\n",
      "indicater                       0\n",
      "dtype: int64\n",
      "True\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Dataset/processdata.csv', encoding='latin-1')\n",
    "date_columns = ['Date.of.Last.Contact', 'Date.of.Diagnostic']\n",
    "data[date_columns] = data[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "data['Survival_Time'] = (data['Date.of.Last.Contact'] - data['Date.of.Diagnostic']).dt.days\n",
    "data.loc[:, 'Survival_Time'] = data['Survival_Time'].replace({-1: 0})\n",
    "data['indicater'] = np.where(data['Date.of.Death'].isna(), 0, 1)\n",
    "# Staring time from 1\n",
    "# data['Survival_Time'] = data['Survival_Time'] + 1\n",
    "\n",
    "# Removing instances with survival time = 0\n",
    "data = data.drop(data[data['Survival_Time'] == 0].index)\n",
    "\n",
    "\n",
    "columns_to_drop = ['Date.of.Death', 'Date.of.Last.Contact', 'Date.of.Diagnostic',\n",
    "                   'Type.of.Death',  # High Correlation with 'Date.of.Death' and events\n",
    "                   ]\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "print(data.isna().sum())\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "        range(len(data)), stratify=data['indicater'], random_state=1, test_size=0.25\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns_to_one_hot = ['RCBP.Name', 'Raca.Color', 'State.Civil', 'Code.Profession', 'Name.Occupation',\n",
    "                              'Status.Address',\n",
    "                              'City.Address', 'Description.of.Topography', 'Topography.Code', 'Morphology.Description',\n",
    "                              'Code.of.Morphology', 'Description.of.Disease', 'Illness.Code', 'Diagnostic.means',\n",
    "                              'Extension',\n",
    "                              #'Type.of.Death' # High Correlation with 'Date.of.Death' and events\n",
    "                      ]\n",
    "\n",
    "# Replace other values that are not in top 9, into \"other\"\n",
    "for column in columns_to_one_hot:\n",
    "    top_9_values = data[column].value_counts().nlargest(9).index\n",
    "    data[column] = data[column].where(data[column].isin(top_9_values), 'other')\n",
    "\n",
    "data = pd.get_dummies(data, columns=columns_to_one_hot)\n",
    "\n",
    "X = data.drop(['Survival_Time', 'indicater'], axis=1)\n",
    "time_all = data['Survival_Time'].values\n",
    "event_all = data['indicater'].values\n",
    "\n",
    "X_train = X.iloc[train_indices].copy()\n",
    "X_test = X.iloc[test_indices].copy()\n",
    "time_train = time_all[train_indices].copy()\n",
    "time_test = time_all[test_indices].copy()\n",
    "event_train = event_all[train_indices].copy()\n",
    "event_test = event_all[test_indices].copy()\n",
    "\n",
    "print((X_test.columns == X_train.columns).all())\n",
    "\n",
    "columns_to_binarize = ['Gender', 'Indicator.of.Rare.Case']    \n",
    "for column in columns_to_binarize:\n",
    "    lb = LabelBinarizer()\n",
    "    X_train[column] = lb.fit_transform(X_train[column])\n",
    "    X_test[column] = lb.transform(X_test[column])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train['Age'] = scaler.fit_transform(X_train[['Age']])\n",
    "X_test['Age'] = scaler.transform(X_test[['Age']])\n",
    "\n",
    "Tmax = time_train.max()\n",
    "num_intervals=7\n",
    "intervals = [(i * (Tmax // num_intervals), (i + 1) * (Tmax // num_intervals)) for i in range(num_intervals)]\n",
    "\n",
    "Y_train = np.zeros((len(time_train), num_intervals), dtype=np.int_)\n",
    "# Until the event happens, value is 1. after that, it is 0\n",
    "for i, time_val in enumerate(time_train):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if time_val > right or (left < time_val <= right):\n",
    "            Y_train[i, j] = 1\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "\n",
    "\n",
    "Y_test = np.zeros((len(time_test), num_intervals), dtype=np.int_)\n",
    "# Until the event happens, value is 1. after that, it is 0\n",
    "for i, time_val in enumerate(time_test):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if time_val > right or (left < time_val <= right):\n",
    "            Y_test[i, j] = 1\n",
    "Y_test = torch.Tensor(Y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Creat mask matrix\n",
    "W_train = np.zeros((len(time_train), num_intervals), dtype=np.int_)\n",
    "# Until the time we know he was alive the value is 1, after that is 0\n",
    "for i, (time_val, event_val) in enumerate(zip(time_train, event_train)):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if event_val == 0 and time_val < left:\n",
    "            W_train[i, j] = 0\n",
    "        else:\n",
    "            W_train[i, j] = 1\n",
    "W_train = torch.Tensor(W_train)\n",
    "\n",
    "\n",
    "\n",
    "# Creat mask matrix\n",
    "W_test = np.zeros((len(time_test), num_intervals), dtype=np.int_)\n",
    "# Until the time we know he was alive the value is 1, after that is 0\n",
    "for i, (time_val, event_val) in enumerate(zip(time_test, event_test)):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if event_val == 0 and time_val < left:\n",
    "            W_test[i, j] = 0\n",
    "        else:\n",
    "            W_test[i, j] = 1\n",
    "W_test = torch.Tensor(W_test)\n",
    "\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == bool:\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == bool:\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Y_train = Y[train_indices]\n",
    "# Y_test = Y[test_indices]\n",
    "# W_train = W[train_indices]\n",
    "# W_test  = W[test_indices]\n",
    "Y_train_transform = [Y_train[:, i:i + 1] for i in range(Y_train.size(1))]\n",
    "Y_test_transform = [Y_test[:, i:i + 1] for i in range(Y_test.size(1))]\n",
    "W_train_transform = [W_train[:, i:i+1] for i in range(W_train.size(1))]\n",
    "W_test_transform = [W_test[:, i:i+1] for i in range(W_test.size(1))]\n",
    "\n",
    "print((W_test_transform[-1] == 0).any())\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"epochs\": 200,\n",
    "    \"clip\": 5.0,\n",
    "    \"lambda_reg\": 0.01,\n",
    "    \"save_path\": \"outputfiles\",\n",
    "    \"eg_k\" : 1, \n",
    "    \"early_stop_patience\":15,\n",
    "})\n",
    "\n",
    "train_dataset = MultiTaskDataset(X_train, Y_train_transform, W_train_transform, event_train)\n",
    "test_dataset = MultiTaskDataset(X_test, Y_test_transform, W_test_transform, event_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:48:13.476255400Z",
     "start_time": "2024-07-01T15:48:13.348255600Z"
    }
   },
   "id": "502e4c2ec860b444"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class EditedCindexOptimized(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(EditedCindexOptimized, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_hat, status):\n",
    "        if not torch.is_tensor(y):\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "        if not torch.is_tensor(y_hat):\n",
    "            y_hat = torch.tensor(y_hat, dtype=torch.float32)\n",
    "        if not torch.is_tensor(status):\n",
    "            status = torch.tensor(status, dtype=torch.float32)\n",
    "\n",
    "        # replacing loop acceleration with matrix calculation\n",
    "        \n",
    "        y_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
    "        y_hat_diff = y_hat.unsqueeze(1) - y_hat.unsqueeze(0)\n",
    "        # status[i] and status[j] mark whether to censored data\n",
    "        status_i = status.unsqueeze(1)\n",
    "        status_j = status.unsqueeze(0)\n",
    "        valid_pairs = torch.logical_or((y_diff < 0) & (status_i == 1), (y_diff > 0) & (status_j == 1)).float()\n",
    "        torch.diagonal(valid_pairs).fill_(0) #Diagonal set to 0 to eliminate interference\n",
    "        concordant_pairs = torch.logical_or((y_diff < 0) & (y_hat_diff < 0)&(status_i == 1),(y_diff > 0) & (y_hat_diff > 0)& (status_j == 1)).float()\n",
    "        torch.diagonal(concordant_pairs).fill_(0) #Diagonal set to 0 to eliminate interference\n",
    "        concordant_pairs = concordant_pairs.float()\n",
    "        c_index = concordant_pairs.sum() / valid_pairs.sum()\n",
    "        return c_index.item()\n",
    "    \n",
    "\n",
    "class OriginalCindexOptimized(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(OriginalCindexOptimized, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_hat, status):\n",
    "        if not torch.is_tensor(y):\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "        if not torch.is_tensor(y_hat):\n",
    "            y_hat = torch.tensor(y_hat, dtype=torch.float32)\n",
    "        if not torch.is_tensor(status):\n",
    "            status = torch.tensor(status, dtype=torch.float32)\n",
    "\n",
    "        # replacing loop acceleration with matrix calculation\n",
    "        \n",
    "        y_diff = y.unsqueeze(1) - y.unsqueeze(0)\n",
    "        y_hat_diff = y_hat.unsqueeze(1) - y_hat.unsqueeze(0)\n",
    "        # status[i] and status[j] mark whether to censored data\n",
    "        status_i = status.unsqueeze(1)\n",
    "        status_j = status.unsqueeze(0)\n",
    "        valid_pairs = torch.logical_or((y_diff <= 0) & (status_i == 1), (y_diff >= 0) & (status_j == 1)).float()\n",
    "        torch.diagonal(valid_pairs).fill_(0) #Diagonal set to 0 to eliminate interference\n",
    "        concordant_pairs = torch.logical_or((y_diff <= 0) & (y_hat_diff <= 0)&(status_i == 1),(y_diff >= 0) & (y_hat_diff >= 0)& (status_j == 1)).float()\n",
    "        torch.diagonal(concordant_pairs).fill_(0) #Diagonal set to 0 to eliminate interference\n",
    "        concordant_pairs = concordant_pairs.float()\n",
    "        c_index = concordant_pairs.sum() / valid_pairs.sum()\n",
    "        return c_index.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:51:55.815831300Z",
     "start_time": "2024-07-01T15:51:55.804630100Z"
    }
   },
   "id": "eba7a83357438fb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "107e9376e504ea17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results for Model with No regularization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cd001ba1e1230e2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:01<06:02,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Training Loss: 3.0994, Average Gradient Norm: 0.0000\n",
      "End of Epoch 0, Average Validation Loss: 2.4092\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 1, Average Training Loss: 2.5994, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:02<02:52,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Validation Loss: 2.5157\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 2, Average Training Loss: 2.4805, Average Gradient Norm: 0.0000\n",
      "End of Epoch 2, Average Validation Loss: 2.4121\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:02<01:24,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3, Average Training Loss: 2.4210, Average Gradient Norm: 0.0000\n",
      "End of Epoch 3, Average Validation Loss: 2.3143\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:02<01:08,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4, Average Training Loss: 2.3663, Average Gradient Norm: 0.0000\n",
      "End of Epoch 4, Average Validation Loss: 2.3614\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:02<00:58,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5, Average Training Loss: 2.3091, Average Gradient Norm: 0.0000\n",
      "End of Epoch 5, Average Validation Loss: 2.6774\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 6, Average Training Loss: 2.3273, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:03<00:52,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6, Average Validation Loss: 2.3145\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 7, Average Training Loss: 2.3066, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:03<00:49,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7, Average Validation Loss: 2.2558\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 8, Average Training Loss: 2.2976, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:03<00:46,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8, Average Validation Loss: 2.3007\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 9, Average Training Loss: 2.2281, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:03<00:44,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9, Average Validation Loss: 2.4172\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 10, Average Training Loss: 2.2526, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:03<00:43,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10, Average Validation Loss: 2.3121\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 11, Average Training Loss: 2.2151, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:04<00:42,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 11, Average Validation Loss: 2.4345\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 12, Average Training Loss: 2.1845, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:04<00:42,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 12, Average Validation Loss: 2.3505\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 13, Average Training Loss: 2.2450, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:04<00:41,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 13, Average Validation Loss: 2.6567\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 14, Average Training Loss: 2.1327, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:04<00:41,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 14, Average Validation Loss: 2.3730\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 15, Average Training Loss: 2.0847, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:05<00:40,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 15, Average Validation Loss: 2.3744\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 16, Average Training Loss: 2.0955, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:05<00:40,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 16, Average Validation Loss: 2.4444\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 17, Average Training Loss: 2.0867, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:05<00:40,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 17, Average Validation Loss: 2.3914\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 18, Average Training Loss: 2.0380, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:05<00:39,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 18, Average Validation Loss: 2.4130\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 19, Average Training Loss: 2.0404, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:05<00:39,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 19, Average Validation Loss: 2.3831\n",
      "Current Learning Rate: 0.000100\n",
      "End of Epoch 20, Average Training Loss: 2.0422, Average Gradient Norm: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:06<00:39,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 20, Average Validation Loss: 2.3904\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:06<00:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 21, Average Training Loss: 2.0645, Average Gradient Norm: 0.0000\n",
      "End of Epoch 21, Average Validation Loss: 2.4035\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:06<00:55,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 22, Average Training Loss: 2.0443, Average Gradient Norm: 0.0000\n",
      "End of Epoch 22, Average Validation Loss: 2.4032\n",
      "Current Learning Rate: 0.000100\n",
      "Early stopping triggered after 23 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MultiTaskModel(X_train.shape[1], Y_train.shape[1])\n",
    "trainer = NoRegularizationTrainer(model,train_loader,test_loader, args)\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:48:29.942514100Z",
     "start_time": "2024-07-01T15:48:22.404662500Z"
    }
   },
   "id": "26a8fe496efc7dce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59f921d97cf20ead"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C-Index by edited verseion calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6119f4cebbe460a6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 8 with best validation loss 2.2558\n",
      "C-index for Training Data: 0.7008\n",
      "C-index for Test Data: 0.6873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "cindex_calculator_optimized = EditedCindexOptimized()\n",
    "\n",
    "trainer.load_best_checkpoint()\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(train_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_train = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Training Data: {c11_train:.4f}\")\n",
    "\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(test_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_test = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Test Data: {c11_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:49:46.898283600Z",
     "start_time": "2024-07-01T15:49:46.543283800Z"
    }
   },
   "id": "725b53e732397c64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C-Index by the calculation you sent me"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58d9cfae7b5a9fda"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 8 with best validation loss 2.2558\n",
      "C-index for Training Data: 0.8738\n",
      "C-index for Test Data: 0.8632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "cindex_calculator_optimized = OriginalCindexOptimized()\n",
    "\n",
    "trainer.load_best_checkpoint()\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(train_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_train = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Training Data: {c11_train:.4f}\")\n",
    "\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(test_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_test = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Test Data: {c11_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:52:05.153020400Z",
     "start_time": "2024-07-01T15:52:04.833020Z"
    }
   },
   "id": "b7fe6a0270f951c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74afbb430987f04d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results for EG Based Regularization Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7fffcb5b82181b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<02:39,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Training Loss: 3.3657, Average Gradient Norm: 2.7779\n",
      "End of Epoch 0, Average Validation Loss: 2.7763\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:01<02:21,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Training Loss: 2.9512, Average Gradient Norm: 2.0895\n",
      "End of Epoch 1, Average Validation Loss: 2.8873\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:02<02:21,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Training Loss: 2.8844, Average Gradient Norm: 2.3869\n",
      "End of Epoch 2, Average Validation Loss: 2.5524\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:02<02:20,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3, Average Training Loss: 2.9157, Average Gradient Norm: 2.3801\n",
      "End of Epoch 3, Average Validation Loss: 2.6977\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:03<02:25,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4, Average Training Loss: 2.8630, Average Gradient Norm: 2.8798\n",
      "End of Epoch 4, Average Validation Loss: 2.3793\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:04<02:28,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5, Average Training Loss: 2.8259, Average Gradient Norm: 2.4332\n",
      "End of Epoch 5, Average Validation Loss: 2.6240\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:05<02:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6, Average Training Loss: 2.8288, Average Gradient Norm: 2.7441\n",
      "End of Epoch 6, Average Validation Loss: 2.8192\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:05<02:18,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7, Average Training Loss: 2.8650, Average Gradient Norm: 2.5949\n",
      "End of Epoch 7, Average Validation Loss: 2.4410\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:06<02:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8, Average Training Loss: 2.8239, Average Gradient Norm: 2.7675\n",
      "End of Epoch 8, Average Validation Loss: 2.5457\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:07<02:29,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9, Average Training Loss: 2.8012, Average Gradient Norm: 2.4840\n",
      "End of Epoch 9, Average Validation Loss: 2.3783\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:08<02:22,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10, Average Training Loss: 2.8176, Average Gradient Norm: 2.8234\n",
      "End of Epoch 10, Average Validation Loss: 2.5329\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:08<02:18,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 11, Average Training Loss: 2.8118, Average Gradient Norm: 2.9679\n",
      "End of Epoch 11, Average Validation Loss: 2.7214\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:09<02:18,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 12, Average Training Loss: 2.7766, Average Gradient Norm: 2.4960\n",
      "End of Epoch 12, Average Validation Loss: 2.5582\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:10<02:14,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 13, Average Training Loss: 2.7384, Average Gradient Norm: 2.5164\n",
      "End of Epoch 13, Average Validation Loss: 2.4957\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:10<02:10,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 14, Average Training Loss: 2.8001, Average Gradient Norm: 2.9076\n",
      "End of Epoch 14, Average Validation Loss: 2.4026\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:11<02:07,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 15, Average Training Loss: 2.8023, Average Gradient Norm: 2.6557\n",
      "End of Epoch 15, Average Validation Loss: 2.8536\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:12<02:13,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 16, Average Training Loss: 2.7700, Average Gradient Norm: 2.2672\n",
      "End of Epoch 16, Average Validation Loss: 2.4479\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:13<02:11,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 17, Average Training Loss: 2.7069, Average Gradient Norm: 2.0411\n",
      "End of Epoch 17, Average Validation Loss: 2.4425\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:13<02:15,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 18, Average Training Loss: 2.7085, Average Gradient Norm: 2.0583\n",
      "End of Epoch 18, Average Validation Loss: 2.4230\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:14<02:17,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 19, Average Training Loss: 2.6967, Average Gradient Norm: 2.4578\n",
      "End of Epoch 19, Average Validation Loss: 2.3980\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:15<02:12,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 20, Average Training Loss: 2.7121, Average Gradient Norm: 2.2763\n",
      "End of Epoch 20, Average Validation Loss: 2.3879\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:16<02:09,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 21, Average Training Loss: 2.6709, Average Gradient Norm: 2.0476\n",
      "End of Epoch 21, Average Validation Loss: 2.3871\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:16<02:11,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 22, Average Training Loss: 2.6997, Average Gradient Norm: 2.2107\n",
      "End of Epoch 22, Average Validation Loss: 2.3913\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:17<02:10,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 23, Average Training Loss: 2.6563, Average Gradient Norm: 2.3533\n",
      "End of Epoch 23, Average Validation Loss: 2.3991\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:18<02:14,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 24, Average Training Loss: 2.6498, Average Gradient Norm: 2.2652\n",
      "End of Epoch 24, Average Validation Loss: 2.4004\n",
      "Current Learning Rate: 0.000100\n",
      "Early stopping triggered after 25 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultiTaskModel(X_train.shape[1], Y_train.shape[1])\n",
    "trainer = EGTrainer(model,train_loader,test_loader, train_dataset, args)\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:53:04.354603100Z",
     "start_time": "2024-07-01T15:52:45.924216500Z"
    }
   },
   "id": "9f4ae92ff570300b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C-Index by edited verseion calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3072ca132264990f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 10 with best validation loss 2.3783\n",
      "C-index for Training Data: 0.6130\n",
      "C-index for Test Data: 0.6075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cindex_calculator_optimized = EditedCindexOptimized()\n",
    "trainer.load_best_checkpoint()\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(train_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_train = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Training Data: {c11_train:.4f}\")\n",
    "\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(test_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_test = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Test Data: {c11_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:54:11.103308500Z",
     "start_time": "2024-07-01T15:54:10.753522900Z"
    }
   },
   "id": "18866a281ffe5bb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C-Index by the calculation you sent me"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e0ed168c755b3cb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 10 with best validation loss 2.3783\n",
      "C-index for Training Data: 0.8798\n",
      "C-index for Test Data: 0.8772\n"
     ]
    }
   ],
   "source": [
    "cindex_calculator_optimized = OriginalCindexOptimized()\n",
    "trainer.load_best_checkpoint()\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(train_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_train = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Training Data: {c11_train:.4f}\")\n",
    "\n",
    "\n",
    "predictions, Y_hat, Y_true, events = trainer.predict(test_loader)\n",
    "# Y_hat = predictions[np.arange(predictions.shape[0]), (Y_hat-1)]\n",
    "c11_test = cindex_calculator_optimized(Y_true, Y_hat, events)\n",
    "print(f\"C-index for Test Data: {c11_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T15:54:14.429858600Z",
     "start_time": "2024-07-01T15:54:14.148858900Z"
    }
   },
   "id": "7a98fc25f2544fdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "edd09d0362a90e8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
