{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:19:20.596295500Z",
     "start_time": "2024-06-23T16:19:18.631033700Z"
    }
   },
   "outputs": [],
   "source": [
    "from algorithm import (\n",
    "                        NoRegularizationTrainer,\n",
    "                        GradientTrainer,\n",
    "                        EGTrainer,\n",
    "                        CSVDataLoader,\n",
    "                        MultiTaskModel,\n",
    "                        MultiTaskDataset,\n",
    "                        mlt_train_test_split,\n",
    "                        # true_values_from_data_loader,\n",
    "                        unique_value_counts,\n",
    "                        Cindex,\n",
    "                        brier_score,\n",
    "                        )\n",
    "import easydict\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on your feedback regarding the c-index value, I have thoroughly investigated the model, dataset, and other evaluation metrics. Here are my findings:\n",
    "\n",
    "Initially, I replaced the random data splitting method with a stratified approach based on events. This revealed an imbalance in the data across different time intervals. Since we are grouping times into seven buckets, the data counts for each bucket are as follow.\n",
    "\n",
    "As you can see, the initial buckets dominate (Which is common in survival data), which suggests that the model will struggle with learning from the later buckets. \n",
    "\n",
    "Additionally, I implemented a learning rate scheduler, early stopping, and best model checkpointing based on the best validation loss. With these setups, I trained the model under three conditions: without any attribution regularization term, with expected gradient as the attribution method, and with only gradient as the attribution method. I calculated C-Index and Integrated Brier Score for these three models.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb572ded1db9f42f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plot_unique_values_count(unique_values, counts, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(unique_values, counts, tick_label=unique_values)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:19:20.618294800Z",
     "start_time": "2024-06-23T16:19:20.600295100Z"
    }
   },
   "id": "3c3232b50f2bd7b9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
      "Counts: tensor([4114, 4060, 1622, 2116, 1631,  893,  256,   63])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl = CSVDataLoader()\n",
    "X, Y, Y_transform, W, W_transform, time_all, event_all = dl.get_data(num_intervals=7)\n",
    "\n",
    "\n",
    "unique_values, counts = unique_value_counts(Y.sum(axis=1))\n",
    "plot_unique_values_count(unique_values, counts, 'Value Counts in Y Tensor')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:19:20.936295100Z",
     "start_time": "2024-06-23T16:19:20.614295Z"
    }
   },
   "id": "dd8b6f37611be6c6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unique_values, counts = np.unique(event_all, return_counts=True)\n",
    "plot_unique_values_count(unique_values, counts, 'Value Counts in Events')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:19:21.001295200Z",
     "start_time": "2024-06-23T16:19:20.926294900Z"
    }
   },
   "id": "8ec3c8a484f1ebf8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the model without any regularization term yields almost the same c-index value, and considering that, based on your initial instructions, the data preprocessing and evaluation metrics implementations are correct, I believe there is no problem with the training process."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b87ee9046842726"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I suggest to use cross validation for better estimation of these mehods."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9a7c25cf55d004f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "657082277c0a6824"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training model with no Regularization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8203b1204e3bbeef"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:01<05:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Training Loss: 1.5235, Average Gradient Norm: 1.7815\n",
      "End of Epoch 0, Average Validation Loss: 1.2065\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:02<04:50,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Training Loss: 1.1061, Average Gradient Norm: 1.7674\n",
      "End of Epoch 1, Average Validation Loss: 1.0537\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:04<06:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Training Loss: 1.0578, Average Gradient Norm: 1.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 26\u001B[0m\n\u001B[0;32m     22\u001B[0m model \u001B[38;5;241m=\u001B[39m MultiTaskModel(in_features, out_features)\n\u001B[0;32m     25\u001B[0m no_reg_trainer \u001B[38;5;241m=\u001B[39m NoRegularizationTrainer(model,train_loader,test_loader,args)\n\u001B[1;32m---> 26\u001B[0m \u001B[43mno_reg_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Data\\Development\\PHD\\Wang\\NLP\\algorithm\\no_reg_trainer.py:69\u001B[0m, in \u001B[0;36mNoRegularizationTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     65\u001B[0m avg_grad_norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(gradient_norms) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(gradient_norms)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEnd of Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Average Training Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Average Gradient Norm: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_grad_norm\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 69\u001B[0m early_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m early_stop:\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Data\\Development\\PHD\\Wang\\NLP\\algorithm\\no_reg_trainer.py:77\u001B[0m, in \u001B[0;36mNoRegularizationTrainer.validate\u001B[1;34m(self, epoch)\u001B[0m\n\u001B[0;32m     75\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m X_val, val_targets, val_masks, event_val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loader:\n\u001B[0;32m     78\u001B[0m         X_val \u001B[38;5;241m=\u001B[39m X_val\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     79\u001B[0m         val_targets \u001B[38;5;241m=\u001B[39m [target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m val_targets]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:316\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[0;32m    256\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    170\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    170\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m--> 141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m    144\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:213\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    211\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    212\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[1;32m--> 213\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dl = CSVDataLoader()\n",
    "X, Y, Y_transform, W, W_transform, time_all, event_all = dl.get_data(num_intervals=7)\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"epochs\": 200,\n",
    "    \"clip\": 5.0,\n",
    "    \"lambda_reg\": 0.01,\n",
    "    \"save_path\": \"outputfiles\",\n",
    "    \"eg_k\" : 5, \n",
    "    \"early_stop_patience\":15,\n",
    "})\n",
    "\n",
    "\n",
    "full_dataset = MultiTaskDataset(X, Y_transform, W_transform, event_all)\n",
    "\n",
    "train_loader, test_loader, train_dataset, test_dataset , in_features, out_features = (\n",
    "    mlt_train_test_split(full_dataset, range(len(X)), event_all, args.batch_size, ratio=0.25))\n",
    "\n",
    "\n",
    "model = MultiTaskModel(in_features, out_features)\n",
    "\n",
    "\n",
    "no_reg_trainer = NoRegularizationTrainer(model,train_loader,test_loader,args)\n",
    "no_reg_trainer.train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:24:17.405090500Z",
     "start_time": "2024-06-23T16:24:12.782831Z"
    }
   },
   "id": "fbcce373bbe23b05"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:17:17.870098300Z",
     "start_time": "2024-06-23T16:17:17.854099800Z"
    }
   },
   "id": "7c27900fa3fd332f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating model with no regularization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "140fb8c13c1f9073"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 13 with best validation loss 1.0396\n",
      "Evaluation On Train Data \n",
      "Y_true Train\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([3057, 3025, 1208, 1593, 1215,  675,  191,   44])\n",
      "Y_hat Train\n",
      "Unique Values: tensor([0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "Counts: tensor([2646, 2475, 1451,  792,  398,   12,    8, 3226])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11008/11008 [00:01<00:00, 8061.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data C-Index = 0.982032060623169,  BScore = 0.06191517515654854\n",
      "\n",
      "Evaluation On Test Data \n",
      "\n",
      "Y_true Test\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([1026, 1009,  404,  507,  406,  214,   64,   18])\n",
      "Y_hat Test\n",
      "Unique Values: tensor([0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "Counts: tensor([ 884,  775,  496,  288,  120,    1,    9, 1075])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3648/3648 [00:00<00:00, 8142.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data C-Index = 0.9798187613487244,  BScore = 0.06714734390115036\n"
     ]
    }
   ],
   "source": [
    "no_reg_trainer.load_best_checkpoint()\n",
    "\n",
    "print(\"Evaluation On Train Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = no_reg_trainer.predict(train_loader)\n",
    "print(\"Y_true Train\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Train\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Train Data C-Index = {cindex_test},  BScore = {bscore_test}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation On Test Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = no_reg_trainer.predict(test_loader)\n",
    "print(\"Y_true Test\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Test\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Test Data C-Index = {cindex_test},  BScore = {bscore_test}\")\n",
    "# print(classification_report(Y_true_test.cpu(), Y_hat_test.cpu()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:17:21.963421200Z",
     "start_time": "2024-06-23T16:17:17.870098300Z"
    }
   },
   "id": "41f8dde9c26d6d90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "328d60a6774138f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "711cdde6c9246c51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training model with Expected Gradient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "735842621fc65281"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:03<11:52,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Training Loss: 2.0793, Average Gradient Norm: 2.5265\n",
      "End of Epoch 0, Average Validation Loss: 1.3944\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:06<11:22,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Training Loss: 1.7410, Average Gradient Norm: 3.5786\n",
      "End of Epoch 1, Average Validation Loss: 1.2652\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:10<11:08,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Training Loss: 1.6960, Average Gradient Norm: 3.6496\n",
      "End of Epoch 2, Average Validation Loss: 1.1809\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:13<11:08,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3, Average Training Loss: 1.6655, Average Gradient Norm: 3.6882\n",
      "End of Epoch 3, Average Validation Loss: 1.1306\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:17<11:05,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4, Average Training Loss: 1.6650, Average Gradient Norm: 3.7638\n",
      "End of Epoch 4, Average Validation Loss: 1.4148\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:20<10:50,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5, Average Training Loss: 1.6515, Average Gradient Norm: 4.1144\n",
      "End of Epoch 5, Average Validation Loss: 1.4252\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:23<10:46,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6, Average Training Loss: 1.6818, Average Gradient Norm: 4.0609\n",
      "End of Epoch 6, Average Validation Loss: 1.1199\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:26<10:37,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7, Average Training Loss: 1.6474, Average Gradient Norm: 4.0987\n",
      "End of Epoch 7, Average Validation Loss: 1.3999\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:30<10:24,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8, Average Training Loss: 1.6381, Average Gradient Norm: 4.3265\n",
      "End of Epoch 8, Average Validation Loss: 1.2568\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 9, Average Training Loss: 1.6313, Average Gradient Norm: 4.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:33<10:18,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9, Average Validation Loss: 1.4031\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:36<10:08,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10, Average Training Loss: 1.6554, Average Gradient Norm: 4.3319\n",
      "End of Epoch 10, Average Validation Loss: 1.2485\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 11, Average Training Loss: 1.6111, Average Gradient Norm: 4.5753\n",
      "End of Epoch 11, Average Validation Loss: 1.3078\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:43<10:07,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 12, Average Training Loss: 1.7026, Average Gradient Norm: 5.1811\n",
      "End of Epoch 12, Average Validation Loss: 1.4090\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:46<10:10,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 13, Average Training Loss: 1.5356, Average Gradient Norm: 3.4420\n",
      "End of Epoch 13, Average Validation Loss: 1.1233\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 14, Average Training Loss: 1.4955, Average Gradient Norm: 4.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:52<13:01,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 14, Average Validation Loss: 1.1278\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 15, Average Training Loss: 1.4858, Average Gradient Norm: 4.5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:59<15:29,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 15, Average Validation Loss: 1.1453\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 16, Average Training Loss: 1.4734, Average Gradient Norm: 4.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [01:06<17:10,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 16, Average Validation Loss: 1.0924\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 17, Average Training Loss: 1.4792, Average Gradient Norm: 5.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [01:13<18:10,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 17, Average Validation Loss: 1.0926\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 18, Average Training Loss: 1.4800, Average Gradient Norm: 5.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:20<18:48,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 18, Average Validation Loss: 1.1251\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 19, Average Training Loss: 1.4839, Average Gradient Norm: 5.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:27<19:24,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 19, Average Validation Loss: 1.0784\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 20, Average Training Loss: 1.4482, Average Gradient Norm: 5.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [01:34<19:33,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 20, Average Validation Loss: 1.0931\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [01:37<16:24,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 21, Average Training Loss: 1.4718, Average Gradient Norm: 5.9844\n",
      "End of Epoch 21, Average Validation Loss: 1.1115\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [01:40<14:15,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 22, Average Training Loss: 1.4632, Average Gradient Norm: 5.9483\n",
      "End of Epoch 22, Average Validation Loss: 1.1776\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [01:43<12:45,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 23, Average Training Loss: 1.4751, Average Gradient Norm: 6.3951\n",
      "End of Epoch 23, Average Validation Loss: 1.0889\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 24, Average Training Loss: 1.4682, Average Gradient Norm: 6.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [01:50<14:23,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 24, Average Validation Loss: 1.0936\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [01:56<15:32,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 25, Average Training Loss: 1.4587, Average Gradient Norm: 6.0276\n",
      "End of Epoch 25, Average Validation Loss: 1.1000\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [01:59<13:42,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 26, Average Training Loss: 1.4485, Average Gradient Norm: 5.9077\n",
      "End of Epoch 26, Average Validation Loss: 1.0942\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [02:03<12:25,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 27, Average Training Loss: 1.4117, Average Gradient Norm: 5.8643\n",
      "End of Epoch 27, Average Validation Loss: 1.0968\n",
      "Current Learning Rate: 0.000100\n",
      "End of Epoch 28, Average Training Loss: 1.4334, Average Gradient Norm: 6.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [02:07<12:22,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 28, Average Validation Loss: 1.0944\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [02:12<13:09,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 29, Average Training Loss: 1.4292, Average Gradient Norm: 5.9661\n",
      "End of Epoch 29, Average Validation Loss: 1.0964\n",
      "Current Learning Rate: 0.000100\n",
      "End of Epoch 30, Average Training Loss: 1.4193, Average Gradient Norm: 6.1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [02:16<12:10,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 30, Average Validation Loss: 1.0979\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [02:20<11:29,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 31, Average Training Loss: 1.4218, Average Gradient Norm: 6.2419\n",
      "End of Epoch 31, Average Validation Loss: 1.0828\n",
      "Current Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [02:23<10:51,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 32, Average Training Loss: 1.4419, Average Gradient Norm: 6.0877\n",
      "End of Epoch 32, Average Validation Loss: 1.0869\n",
      "Current Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [02:27<10:32,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 33, Average Training Loss: 1.4277, Average Gradient Norm: 5.9502\n",
      "End of Epoch 33, Average Validation Loss: 1.0896\n",
      "Current Learning Rate: 0.000010\n",
      "End of Epoch 34, Average Training Loss: 1.4209, Average Gradient Norm: 6.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [02:30<12:14,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 34, Average Validation Loss: 1.0924\n",
      "Current Learning Rate: 0.000010\n",
      "Early stopping triggered after 35 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dl = CSVDataLoader()\n",
    "X, Y, Y_transform, W, W_transform, time_all, event_all = dl.get_data()\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"epochs\": 200,\n",
    "    \"clip\": 5.0,\n",
    "    \"lambda_reg\": 0.01,\n",
    "    \"save_path\": \"outputfiles\",\n",
    "    \"eg_k\" : 1, \n",
    "    \"early_stop_patience\":15,\n",
    "})\n",
    "\n",
    "\n",
    "full_dataset = MultiTaskDataset(X, Y_transform, W_transform, event_all)\n",
    "\n",
    "train_loader, test_loader, train_dataset, test_dataset , in_features, out_features = (\n",
    "    mlt_train_test_split(full_dataset, range(len(X)), event_all, args.batch_size, ratio=0.25))\n",
    "\n",
    "\n",
    "model = MultiTaskModel(in_features, out_features)\n",
    "\n",
    "\n",
    "eg_trainer = EGTrainer(model, train_loader, test_loader, train_dataset, args)\n",
    "eg_trainer.train()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:26:51.384172800Z",
     "start_time": "2024-06-23T16:24:20.651076100Z"
    }
   },
   "id": "bf80e32972f206e8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T17:00:31.324294500Z",
     "start_time": "2024-06-22T17:00:31.307291900Z"
    }
   },
   "id": "87606111220eca20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating model with expected gradient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a78acc395558da7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 20 with best validation loss 1.0784\n",
      "Evaluation On Train Data \n",
      "Y_true Train\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([3051, 3021, 1212, 1599, 1217,  674,  190,   44])\n",
      "Y_hat Train\n",
      "Unique Values: tensor([0, 1, 2, 3, 4, 7], dtype=torch.int32)\n",
      "Counts: tensor([2735, 2957,  861,  721,  355, 3379])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11008/11008 [00:01<00:00, 7213.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data C-Index = 0.9753935933113098,  BScore = 0.06693808592112391\n",
      "\n",
      "Evaluation On Test Data \n",
      "\n",
      "Y_true Test\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([1026, 1009,  404,  507,  406,  214,   64,   18])\n",
      "Y_hat Test\n",
      "Unique Values: tensor([0, 1, 2, 3, 4, 7], dtype=torch.int32)\n",
      "Counts: tensor([ 918,  966,  297,  222,  125, 1120])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3648/3648 [00:00<00:00, 8017.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data C-Index = 0.9744025468826294,  BScore = 0.06894147858088405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eg_trainer.load_best_checkpoint()\n",
    "\n",
    "print(\"Evaluation On Train Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = eg_trainer.predict(train_loader)\n",
    "print(\"Y_true Train\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Train\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Train Data C-Index = {cindex_test},  BScore = {bscore_test}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation On Test Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = eg_trainer.predict(test_loader)\n",
    "print(\"Y_true Test\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Test\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Test Data C-Index = {cindex_test},  BScore = {bscore_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:28:01.381569100Z",
     "start_time": "2024-06-23T16:27:58.474010Z"
    }
   },
   "id": "b44fda9f25c3572a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35d43fb054e095c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training model with gradient attribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fb063d80390457"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:02<08:55,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Training Loss: 2.3730, Average Gradient Norm: 5.1345\n",
      "End of Epoch 0, Average Validation Loss: 1.8684\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 1, Average Training Loss: 2.0289, Average Gradient Norm: 6.8747\n",
      "End of Epoch 1, Average Validation Loss: 1.9101\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:07<08:29,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Training Loss: 1.9696, Average Gradient Norm: 7.7292\n",
      "End of Epoch 2, Average Validation Loss: 1.8523\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:10<08:19,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3, Average Training Loss: 1.9513, Average Gradient Norm: 8.1893\n",
      "End of Epoch 3, Average Validation Loss: 1.8048\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:12<08:09,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4, Average Training Loss: 1.9305, Average Gradient Norm: 8.8037\n",
      "End of Epoch 4, Average Validation Loss: 1.7990\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:15<08:14,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 5, Average Training Loss: 1.9189, Average Gradient Norm: 9.5772\n",
      "End of Epoch 5, Average Validation Loss: 1.8027\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:17<08:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 6, Average Training Loss: 1.9184, Average Gradient Norm: 9.3477\n",
      "End of Epoch 6, Average Validation Loss: 1.8720\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:20<08:08,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 7, Average Training Loss: 1.9079, Average Gradient Norm: 9.8652\n",
      "End of Epoch 7, Average Validation Loss: 1.8324\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:22<07:59,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 8, Average Training Loss: 1.9285, Average Gradient Norm: 10.0026\n",
      "End of Epoch 8, Average Validation Loss: 1.8354\n",
      "Current Learning Rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:25<07:56,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 9, Average Training Loss: 1.9396, Average Gradient Norm: 9.1023\n",
      "End of Epoch 9, Average Validation Loss: 1.8197\n",
      "Current Learning Rate: 0.010000\n",
      "End of Epoch 10, Average Training Loss: 1.9323, Average Gradient Norm: 9.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:27<07:54,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 10, Average Validation Loss: 1.8249\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:30<07:49,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 11, Average Training Loss: 1.8061, Average Gradient Norm: 10.4674\n",
      "End of Epoch 11, Average Validation Loss: 1.7959\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 12, Average Training Loss: 1.7883, Average Gradient Norm: 13.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:32<07:50,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 12, Average Validation Loss: 1.7887\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:35<07:39,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 13, Average Training Loss: 1.7808, Average Gradient Norm: 14.7023\n",
      "End of Epoch 13, Average Validation Loss: 1.7790\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 14, Average Training Loss: 1.7799, Average Gradient Norm: 15.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:39<09:32,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 14, Average Validation Loss: 1.7803\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 15, Average Training Loss: 1.7713, Average Gradient Norm: 16.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:45<11:30,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 15, Average Validation Loss: 1.7755\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 16, Average Training Loss: 1.7681, Average Gradient Norm: 17.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:50<12:51,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 16, Average Validation Loss: 1.7853\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 17, Average Training Loss: 1.7713, Average Gradient Norm: 18.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:55<13:44,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 17, Average Validation Loss: 1.7697\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 18, Average Training Loss: 1.7638, Average Gradient Norm: 18.5826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:01<14:29,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 18, Average Validation Loss: 1.7768\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 19, Average Training Loss: 1.7698, Average Gradient Norm: 20.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:06<14:48,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 19, Average Validation Loss: 1.7809\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 20, Average Training Loss: 1.7673, Average Gradient Norm: 20.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [01:11<14:56,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 20, Average Validation Loss: 1.7825\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 21, Average Training Loss: 1.7618, Average Gradient Norm: 21.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [01:16<15:03,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 21, Average Validation Loss: 1.7987\n",
      "Current Learning Rate: 0.001000\n",
      "End of Epoch 22, Average Training Loss: 1.7624, Average Gradient Norm: 21.7413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [01:21<15:01,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 22, Average Validation Loss: 1.7820\n",
      "Current Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [01:25<13:41,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 23, Average Training Loss: 1.7645, Average Gradient Norm: 20.6108\n",
      "End of Epoch 23, Average Validation Loss: 1.7857\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [01:27<11:39,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 24, Average Training Loss: 1.7445, Average Gradient Norm: 20.1284\n",
      "End of Epoch 24, Average Validation Loss: 1.7843\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [01:30<10:15,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 25, Average Training Loss: 1.7493, Average Gradient Norm: 23.1301\n",
      "End of Epoch 25, Average Validation Loss: 1.7819\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [01:33<09:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 26, Average Training Loss: 1.7418, Average Gradient Norm: 22.9858\n",
      "End of Epoch 26, Average Validation Loss: 1.7828\n",
      "Current Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [01:35<08:32,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 27, Average Training Loss: 1.7408, Average Gradient Norm: 23.8540\n",
      "End of Epoch 27, Average Validation Loss: 1.7811\n",
      "Current Learning Rate: 0.000100\n",
      "End of Epoch 28, Average Training Loss: 1.7347, Average Gradient Norm: 22.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [01:39<09:04,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 28, Average Validation Loss: 1.7836\n",
      "Current Learning Rate: 0.000100\n",
      "End of Epoch 29, Average Training Loss: 1.7393, Average Gradient Norm: 23.4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [01:44<10:45,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 29, Average Validation Loss: 1.7852\n",
      "Current Learning Rate: 0.000010\n",
      "End of Epoch 30, Average Training Loss: 1.7417, Average Gradient Norm: 21.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [01:49<11:51,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 30, Average Validation Loss: 1.7846\n",
      "Current Learning Rate: 0.000010\n",
      "End of Epoch 31, Average Training Loss: 1.7341, Average Gradient Norm: 21.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [01:52<10:52,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 31, Average Validation Loss: 1.7846\n",
      "Current Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [01:55<10:04,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 32, Average Training Loss: 1.7440, Average Gradient Norm: 23.4276\n",
      "End of Epoch 32, Average Validation Loss: 1.7842\n",
      "Current Learning Rate: 0.000010\n",
      "Early stopping triggered after 33 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dl = CSVDataLoader()\n",
    "X, Y, Y_transform, W, W_transform, time_all, event_all = dl.get_data()\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"epochs\": 200,\n",
    "    \"clip\": 5.0,\n",
    "    \"lambda_reg\": 0.01,\n",
    "    \"save_path\": \"outputfiles\",\n",
    "    \"eg_k\" : 5, \n",
    "    \"early_stop_patience\":15,\n",
    "})\n",
    "\n",
    "\n",
    "full_dataset = MultiTaskDataset(X, Y_transform, W_transform, event_all)\n",
    "\n",
    "train_loader, test_loader, train_dataset, test_dataset , in_features, out_features = (\n",
    "    mlt_train_test_split(full_dataset, range(len(X)), event_all, args.batch_size, ratio=0.25))\n",
    "\n",
    "\n",
    "model = MultiTaskModel(in_features, out_features)\n",
    "\n",
    "\n",
    "g_trainer = GradientTrainer(model, train_loader, test_loader, args)\n",
    "g_trainer.train()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:30:01.957406400Z",
     "start_time": "2024-06-23T16:28:06.604361700Z"
    }
   },
   "id": "f191f52496138c33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6cfac2b6a63a52f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating model with gradient attribution on test data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f3dda0872474c6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint at epoch 18 with best validation loss 1.7697\n",
      "Evaluation On Train Data \n",
      "Y_true Train\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([3059, 3023, 1207, 1594, 1217,  673,  191,   44])\n",
      "Y_hat Train\n",
      "Unique Values: tensor([0, 2, 3, 4], dtype=torch.int32)\n",
      "Counts: tensor([5298,   88, 1662, 3960])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11008/11008 [00:01<00:00, 7757.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data C-Index = 0.9804827570915222,  BScore = 0.13497566320080706\n",
      "\n",
      "Evaluation On Test Data \n",
      "\n",
      "Y_true Test\n",
      "Unique Values: tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "Counts: tensor([1026, 1009,  404,  507,  406,  214,   64,   18])\n",
      "Y_hat Test\n",
      "Unique Values: tensor([0, 2, 3, 4], dtype=torch.int32)\n",
      "Counts: tensor([1730,   23,  581, 1314])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3648/3648 [00:00<00:00, 7899.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data C-Index = 0.9798423051834106,  BScore = 0.14150042586263553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "g_trainer.load_best_checkpoint()\n",
    "\n",
    "print(\"Evaluation On Train Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = g_trainer.predict(train_loader)\n",
    "print(\"Y_true Train\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Train\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Train Data C-Index = {cindex_test},  BScore = {bscore_test}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation On Test Data \\n\")\n",
    "\n",
    "predictions, Y_hat, Y_true, events = g_trainer.predict(test_loader)\n",
    "print(\"Y_true Test\")\n",
    "unique_value_counts(Y_true)\n",
    "print(\"Y_hat Test\")\n",
    "unique_value_counts(Y_hat)\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "cindex_test = cindex_calculator(Y_true, Y_hat, events)\n",
    "bscore_test = brier_score(event_all, Y, events, Y_true, predictions)\n",
    "print(f\"Test Data C-Index = {cindex_test},  BScore = {bscore_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T16:30:07.861177200Z",
     "start_time": "2024-06-23T16:30:04.986323300Z"
    }
   },
   "id": "dc7ab8615be4cd18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3767c42b6813674"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6be53d1a12fbc3e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
