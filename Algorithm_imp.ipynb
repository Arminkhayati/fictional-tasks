{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:54.874314900Z",
     "start_time": "2024-06-15T13:17:53.229301800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import numpy as np\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import numpy as np\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4d947b03ebf49c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7408\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Gender       Age  Indicator.of.Rare.Case  Survival_Time  indicater  \\\n0       1  0.283019                       0              0          1   \n1       1  0.490566                       0              0          1   \n2       1  0.698113                       0              0          1   \n3       1  0.556604                       0              0          1   \n4       0  0.122642                       0           3959          0   \n\n   RCBP.Name_RCBP BELO HORIZONTE  RCBP.Name_RCBP CAMPINAS-UNICAMP  \\\n0                          False                             True   \n1                          False                             True   \n2                          False                             True   \n3                          False                             True   \n4                          False                             True   \n\n   RCBP.Name_RCBP DISTRITO FEDERAL  RCBP.Name_RCBP DRS BARRETOS  \\\n0                            False                        False   \n1                            False                        False   \n2                            False                        False   \n3                            False                        False   \n4                            False                        False   \n\n   RCBP.Name_RCBP FORTALEZA  ...  Diagnostic.means_PESQUISA  \\\n0                     False  ...                      False   \n1                     False  ...                      False   \n2                     False  ...                      False   \n3                     False  ...                      False   \n4                     False  ...                      False   \n\n   Diagnostic.means_SDO  Diagnostic.means_other  Extension_IN SITU  \\\n0                  True                   False              False   \n1                  True                   False              False   \n2                  True                   False              False   \n3                  True                   False              False   \n4                 False                   False              False   \n\n   Extension_LOCALIZADO  Extension_MET?STASE  Extension_N?O SE APLICA  \\\n0                 False                 True                    False   \n1                 False                 True                    False   \n2                 False                False                     True   \n3                 False                 True                    False   \n4                 False                False                     True   \n\n   Type.of.Death_C?NCER  Type.of.Death_N?O C?NCER  Type.of.Death_other  \n0                  True                     False                False  \n1                  True                     False                False  \n2                  True                     False                False  \n3                  True                     False                False  \n4                 False                     False                 True  \n\n[5 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Indicator.of.Rare.Case</th>\n      <th>Survival_Time</th>\n      <th>indicater</th>\n      <th>RCBP.Name_RCBP BELO HORIZONTE</th>\n      <th>RCBP.Name_RCBP CAMPINAS-UNICAMP</th>\n      <th>RCBP.Name_RCBP DISTRITO FEDERAL</th>\n      <th>RCBP.Name_RCBP DRS BARRETOS</th>\n      <th>RCBP.Name_RCBP FORTALEZA</th>\n      <th>...</th>\n      <th>Diagnostic.means_PESQUISA</th>\n      <th>Diagnostic.means_SDO</th>\n      <th>Diagnostic.means_other</th>\n      <th>Extension_IN SITU</th>\n      <th>Extension_LOCALIZADO</th>\n      <th>Extension_MET?STASE</th>\n      <th>Extension_N?O SE APLICA</th>\n      <th>Type.of.Death_C?NCER</th>\n      <th>Type.of.Death_N?O C?NCER</th>\n      <th>Type.of.Death_other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.283019</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.490566</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.698113</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.556604</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.122642</td>\n      <td>0</td>\n      <td>3959</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/processdata.csv', encoding='latin-1')\n",
    "data = df\n",
    "\n",
    "date_columns = ['Date.of.Last.Contact', 'Date.of.Diagnostic']\n",
    "data[date_columns] = data[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "has_na = data[date_columns].isna().any(axis=1)\n",
    "\n",
    "# My comment: why not death time - contact time?\n",
    "if has_na.any():\n",
    "    data['Survival_Time'] = (data['Date.of.Last.Contact'] - data['Date.of.Diagnostic']).dt.days\n",
    "else:\n",
    "    data['Survival_Time'] = (data['Date.of.Last.Contact'] - data['Date.of.Diagnostic']).dt.days\n",
    "    \n",
    "data.loc[:, 'Survival_Time'] = data['Survival_Time'].replace({-1:0})\n",
    "\n",
    "data['indicater'] = np.where(data['Date.of.Death'].isna(), 0, 1)\n",
    "columns_to_drop = ['Date.of.Death', 'Date.of.Last.Contact', 'Date.of.Diagnostic']\n",
    "\n",
    "\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
    "\n",
    "\n",
    "columns_to_one_hot = ['RCBP.Name', 'Raca.Color', 'State.Civil', 'Code.Profession', 'Name.Occupation', 'Status.Address',\n",
    "                      'City.Address', 'Description.of.Topography', 'Topography.Code', 'Morphology.Description',\n",
    "                      'Code.of.Morphology', 'Description.of.Disease', 'Illness.Code', 'Diagnostic.means', 'Extension',\n",
    "                      'Type.of.Death']\n",
    "\n",
    "# Replace other values that are not in top 9, into \"other\"\n",
    "for column in columns_to_one_hot:\n",
    "    top_9_values = data[column].value_counts().nlargest(9).index\n",
    "    data[column] = data[column].where(data[column].isin(top_9_values), 'other')\n",
    "\n",
    "data = pd.get_dummies(data, columns=columns_to_one_hot)\n",
    "\n",
    "columns_to_binarize = ['Gender', 'Indicator.of.Rare.Case']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "for column in columns_to_binarize:\n",
    "    data[column] = lb.fit_transform(data[column])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['Age'] = scaler.fit_transform(data[['Age']])\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(['Survival_Time', 'indicater'], axis=1)\n",
    "time_all = data['Survival_Time'].values\n",
    "event_all = data['indicater'].values\n",
    "max_time = data['Survival_Time'].max()\n",
    "print(max_time)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:55.443825300Z",
     "start_time": "2024-06-15T13:17:55.319314700Z"
    }
   },
   "id": "6e216450423b1b0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14755, 7])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Take the maximum time and divide it into any number of intervals\n",
    "Tmax = 7500\n",
    "num_intervals = 7\n",
    "\n",
    "intervals = [(i * (Tmax // num_intervals), (i + 1) * (Tmax // num_intervals)) for i in range(num_intervals)]\n",
    "\n",
    "Y = np.zeros((len(time_all), num_intervals), dtype=np.int_)\n",
    "\n",
    "# Until the event happens, value is 1. after that, it is 0\n",
    "for i, time_val in enumerate(time_all):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if time_val > right or (left < time_val <= right):\n",
    "            Y[i, j] = 1\n",
    "\n",
    "Y = torch.Tensor(Y)\n",
    "\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:55.741825600Z",
     "start_time": "2024-06-15T13:17:55.643825500Z"
    }
   },
   "id": "7982f1558b932fbc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       Gender       Age  Indicator.of.Rare.Case  Survival_Time  indicater  \\\n4           0  0.122642                       0           3959          0   \n14          0  0.811321                       0           3595          0   \n15          0  0.415094                       0           1727          1   \n33          0  0.594340                       0           3624          0   \n34          0  0.698113                       0           1808          0   \n...       ...       ...                     ...            ...        ...   \n14747       1  0.433962                       0           1313          1   \n14748       0  0.518868                       0           1147          1   \n14749       1  0.707547                       0           1134          1   \n14750       0  0.613208                       0           1475          1   \n14751       1  0.528302                       0           1302          1   \n\n       RCBP.Name_RCBP BELO HORIZONTE  RCBP.Name_RCBP CAMPINAS-UNICAMP  \\\n4                              False                             True   \n14                             False                             True   \n15                             False                             True   \n33                             False                             True   \n34                             False                             True   \n...                              ...                              ...   \n14747                          False                            False   \n14748                          False                            False   \n14749                          False                            False   \n14750                          False                            False   \n14751                          False                            False   \n\n       RCBP.Name_RCBP DISTRITO FEDERAL  RCBP.Name_RCBP DRS BARRETOS  \\\n4                                False                        False   \n14                               False                        False   \n15                               False                        False   \n33                               False                        False   \n34                               False                        False   \n...                                ...                          ...   \n14747                            False                        False   \n14748                            False                        False   \n14749                            False                        False   \n14750                            False                        False   \n14751                            False                        False   \n\n       RCBP.Name_RCBP FORTALEZA  ...  Diagnostic.means_PESQUISA  \\\n4                         False  ...                      False   \n14                        False  ...                      False   \n15                        False  ...                      False   \n33                        False  ...                      False   \n34                        False  ...                      False   \n...                         ...  ...                        ...   \n14747                     False  ...                      False   \n14748                     False  ...                      False   \n14749                     False  ...                      False   \n14750                     False  ...                      False   \n14751                     False  ...                      False   \n\n       Diagnostic.means_SDO  Diagnostic.means_other  Extension_IN SITU  \\\n4                     False                   False              False   \n14                    False                   False              False   \n15                    False                   False               True   \n33                    False                   False              False   \n34                    False                   False               True   \n...                     ...                     ...                ...   \n14747                 False                   False              False   \n14748                 False                   False              False   \n14749                 False                   False              False   \n14750                 False                   False              False   \n14751                 False                   False              False   \n\n       Extension_LOCALIZADO  Extension_MET?STASE  Extension_N?O SE APLICA  \\\n4                     False                False                     True   \n14                    False                False                     True   \n15                    False                False                    False   \n33                    False                False                     True   \n34                    False                False                    False   \n...                     ...                  ...                      ...   \n14747                 False                False                     True   \n14748                 False                False                     True   \n14749                 False                False                     True   \n14750                 False                False                     True   \n14751                 False                False                     True   \n\n       Type.of.Death_C?NCER  Type.of.Death_N?O C?NCER  Type.of.Death_other  \n4                     False                     False                 True  \n14                    False                     False                 True  \n15                     True                     False                False  \n33                    False                     False                 True  \n34                    False                     False                 True  \n...                     ...                       ...                  ...  \n14747                  True                     False                False  \n14748                  True                     False                False  \n14749                  True                     False                False  \n14750                  True                     False                False  \n14751                  True                     False                False  \n\n[6692 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Indicator.of.Rare.Case</th>\n      <th>Survival_Time</th>\n      <th>indicater</th>\n      <th>RCBP.Name_RCBP BELO HORIZONTE</th>\n      <th>RCBP.Name_RCBP CAMPINAS-UNICAMP</th>\n      <th>RCBP.Name_RCBP DISTRITO FEDERAL</th>\n      <th>RCBP.Name_RCBP DRS BARRETOS</th>\n      <th>RCBP.Name_RCBP FORTALEZA</th>\n      <th>...</th>\n      <th>Diagnostic.means_PESQUISA</th>\n      <th>Diagnostic.means_SDO</th>\n      <th>Diagnostic.means_other</th>\n      <th>Extension_IN SITU</th>\n      <th>Extension_LOCALIZADO</th>\n      <th>Extension_MET?STASE</th>\n      <th>Extension_N?O SE APLICA</th>\n      <th>Type.of.Death_C?NCER</th>\n      <th>Type.of.Death_N?O C?NCER</th>\n      <th>Type.of.Death_other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.122642</td>\n      <td>0</td>\n      <td>3959</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0.811321</td>\n      <td>0</td>\n      <td>3595</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>0.415094</td>\n      <td>0</td>\n      <td>1727</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0</td>\n      <td>0.594340</td>\n      <td>0</td>\n      <td>3624</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0</td>\n      <td>0.698113</td>\n      <td>0</td>\n      <td>1808</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14747</th>\n      <td>1</td>\n      <td>0.433962</td>\n      <td>0</td>\n      <td>1313</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14748</th>\n      <td>0</td>\n      <td>0.518868</td>\n      <td>0</td>\n      <td>1147</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14749</th>\n      <td>1</td>\n      <td>0.707547</td>\n      <td>0</td>\n      <td>1134</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14750</th>\n      <td>0</td>\n      <td>0.613208</td>\n      <td>0</td>\n      <td>1475</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14751</th>\n      <td>1</td>\n      <td>0.528302</td>\n      <td>0</td>\n      <td>1302</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>6692 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Survival_Time']>1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:55.910824900Z",
     "start_time": "2024-06-15T13:17:55.857825100Z"
    }
   },
   "id": "b4428c1ef5bfb4e4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "indicater\n1    10210\n0     4545\nName: count, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['indicater'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:56.106825100Z",
     "start_time": "2024-06-15T13:17:56.062825700Z"
    }
   },
   "id": "f70b57a214ec3f87"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       Gender       Age  Indicator.of.Rare.Case  Survival_Time  indicater  \\\n4           0  0.122642                       0           3959          0   \n14          0  0.811321                       0           3595          0   \n33          0  0.594340                       0           3624          0   \n34          0  0.698113                       0           1808          0   \n35          0  0.566038                       0           2567          0   \n...       ...       ...                     ...            ...        ...   \n14163       0  0.622642                       0           3449          0   \n14164       0  0.622642                       0           3450          0   \n14165       1  0.660377                       0           4789          0   \n14166       1  0.679245                       0           3303          0   \n14167       0  0.584906                       0           3655          0   \n\n       RCBP.Name_RCBP BELO HORIZONTE  RCBP.Name_RCBP CAMPINAS-UNICAMP  \\\n4                              False                             True   \n14                             False                             True   \n33                             False                             True   \n34                             False                             True   \n35                             False                             True   \n...                              ...                              ...   \n14163                          False                            False   \n14164                          False                            False   \n14165                          False                            False   \n14166                          False                            False   \n14167                          False                            False   \n\n       RCBP.Name_RCBP DISTRITO FEDERAL  RCBP.Name_RCBP DRS BARRETOS  \\\n4                                False                        False   \n14                               False                        False   \n33                               False                        False   \n34                               False                        False   \n35                               False                        False   \n...                                ...                          ...   \n14163                            False                         True   \n14164                            False                         True   \n14165                            False                         True   \n14166                            False                         True   \n14167                            False                         True   \n\n       RCBP.Name_RCBP FORTALEZA  ...  Diagnostic.means_PESQUISA  \\\n4                         False  ...                      False   \n14                        False  ...                      False   \n33                        False  ...                      False   \n34                        False  ...                      False   \n35                        False  ...                      False   \n...                         ...  ...                        ...   \n14163                     False  ...                      False   \n14164                     False  ...                      False   \n14165                     False  ...                      False   \n14166                     False  ...                      False   \n14167                     False  ...                      False   \n\n       Diagnostic.means_SDO  Diagnostic.means_other  Extension_IN SITU  \\\n4                     False                   False              False   \n14                    False                   False              False   \n33                    False                   False              False   \n34                    False                   False               True   \n35                    False                   False              False   \n...                     ...                     ...                ...   \n14163                 False                   False              False   \n14164                 False                   False              False   \n14165                 False                   False              False   \n14166                 False                   False              False   \n14167                 False                   False               True   \n\n       Extension_LOCALIZADO  Extension_MET?STASE  Extension_N?O SE APLICA  \\\n4                     False                False                     True   \n14                    False                False                     True   \n33                    False                False                     True   \n34                    False                False                    False   \n35                     True                False                    False   \n...                     ...                  ...                      ...   \n14163                  True                False                    False   \n14164                  True                False                    False   \n14165                  True                False                    False   \n14166                  True                False                    False   \n14167                 False                False                    False   \n\n       Type.of.Death_C?NCER  Type.of.Death_N?O C?NCER  Type.of.Death_other  \n4                     False                     False                 True  \n14                    False                     False                 True  \n33                    False                     False                 True  \n34                    False                     False                 True  \n35                    False                     False                 True  \n...                     ...                       ...                  ...  \n14163                 False                     False                 True  \n14164                 False                     False                 True  \n14165                 False                     False                 True  \n14166                 False                     False                 True  \n14167                 False                     False                 True  \n\n[4545 rows x 140 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Indicator.of.Rare.Case</th>\n      <th>Survival_Time</th>\n      <th>indicater</th>\n      <th>RCBP.Name_RCBP BELO HORIZONTE</th>\n      <th>RCBP.Name_RCBP CAMPINAS-UNICAMP</th>\n      <th>RCBP.Name_RCBP DISTRITO FEDERAL</th>\n      <th>RCBP.Name_RCBP DRS BARRETOS</th>\n      <th>RCBP.Name_RCBP FORTALEZA</th>\n      <th>...</th>\n      <th>Diagnostic.means_PESQUISA</th>\n      <th>Diagnostic.means_SDO</th>\n      <th>Diagnostic.means_other</th>\n      <th>Extension_IN SITU</th>\n      <th>Extension_LOCALIZADO</th>\n      <th>Extension_MET?STASE</th>\n      <th>Extension_N?O SE APLICA</th>\n      <th>Type.of.Death_C?NCER</th>\n      <th>Type.of.Death_N?O C?NCER</th>\n      <th>Type.of.Death_other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.122642</td>\n      <td>0</td>\n      <td>3959</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0.811321</td>\n      <td>0</td>\n      <td>3595</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0</td>\n      <td>0.594340</td>\n      <td>0</td>\n      <td>3624</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0</td>\n      <td>0.698113</td>\n      <td>0</td>\n      <td>1808</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0</td>\n      <td>0.566038</td>\n      <td>0</td>\n      <td>2567</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14163</th>\n      <td>0</td>\n      <td>0.622642</td>\n      <td>0</td>\n      <td>3449</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14164</th>\n      <td>0</td>\n      <td>0.622642</td>\n      <td>0</td>\n      <td>3450</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14165</th>\n      <td>1</td>\n      <td>0.660377</td>\n      <td>0</td>\n      <td>4789</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14166</th>\n      <td>1</td>\n      <td>0.679245</td>\n      <td>0</td>\n      <td>3303</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14167</th>\n      <td>0</td>\n      <td>0.584906</td>\n      <td>0</td>\n      <td>3655</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>4545 rows × 140 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['indicater']==0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:56.294827200Z",
     "start_time": "2024-06-15T13:17:56.203825500Z"
    }
   },
   "id": "bbd1cdbd6158e093"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Creat mask matrix\n",
    "W = np.zeros((len(time_all), num_intervals), dtype=np.int_)\n",
    "\n",
    "# Until the time we know he was alive the value is 1, after that is 0\n",
    "for i, (time_val, event_val) in enumerate(zip(time_all, event_all)):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if event_val == 0 and time_val < left:\n",
    "            W[i, j] = 0\n",
    "        else:\n",
    "            W[i, j] = 1\n",
    "\n",
    "W = torch.Tensor(W)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:56.480825500Z",
     "start_time": "2024-06-15T13:17:56.441825900Z"
    }
   },
   "id": "aee8a942a43ad246"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# change the batch size from 1024 to 3222 to improve the performance\n",
    "# created by Xinyu modified by Jingyan\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 2048,\n",
    "    \"cuda\": True, # should set it to be true when using gpu, otherwise data would be on two devices\n",
    "    \"lr\": 0.05,\n",
    "    \"seed\": 1111,\n",
    "    \"reduce_rate\": 0.95,\n",
    "    \"epochs\": 20,\n",
    "    \"clip\": 5.0,\n",
    "    \"log_interval\":10,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:57.293825100Z",
     "start_time": "2024-06-15T13:17:57.276938200Z"
    }
   },
   "id": "4dea0085b9de1032"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14755, 138])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].dtype == bool:\n",
    "        X[col] = X[col].astype(int)\n",
    "X_use = torch.tensor(X.values, dtype=torch.float32)\n",
    "X_use.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:57.647825100Z",
     "start_time": "2024-06-15T13:17:57.615825700Z"
    }
   },
   "id": "e044d45dbc19fff8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14755, 1])\n",
      "torch.Size([14755, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert n*m data into m * n * 1 \n",
    "Y_transform = [Y[:, i:i+1] for i in range(Y.size(1))]\n",
    "print(Y_transform[0].shape)\n",
    "W_transform = [W[:, i:i+1] for i in range(W.size(1))]\n",
    "print(W_transform[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:58.342599200Z",
     "start_time": "2024-06-15T13:17:58.318599200Z"
    }
   },
   "id": "7fb75f8a97c41835"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Jingyan adds the dataloader\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, data, targets, masks, event_all):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.masks = masks\n",
    "        self.event_all = event_all\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], [self.targets[i][idx] for i in range(len(self.targets))], [self.masks[i][idx] for i in range(len(self.masks))], self.event_all[idx]\n",
    "\n",
    "\n",
    "#Xinyu\n",
    "full_dataset = MultiTaskDataset(X_use, Y_transform, W_transform, event_all)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:58.681598600Z",
     "start_time": "2024-06-15T13:17:58.656599500Z"
    }
   },
   "id": "2c560d3656abe8b8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 138])\n",
      "7 torch.Size([2048, 1])\n",
      "7 torch.Size([2048, 1])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "for x, y, w, e in train_loader:\n",
    "    print(x.shape)\n",
    "    print(len(y), y[0].shape)\n",
    "    print(len(w), w[0].shape)\n",
    "    print(e.shape)\n",
    "    in_features = x.shape[1]\n",
    "    out_features = len(y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:17:59.613599400Z",
     "start_time": "2024-06-15T13:17:59.532599Z"
    }
   },
   "id": "ef00714e2ad3279b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d65fa65c857213"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Made by Xinyu and modified by Dr.Li and Jingyan\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.num_tasks = out_features\n",
    "        self.input_features = in_features\n",
    "\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1)\n",
    "        )\n",
    "        # A Classic Multi Task Learning Framework\n",
    "        self.task_layers = nn.ModuleList([nn.Linear(128, 1) for _ in range(out_features)])#after your papaer I decided to use MTL to solve this prob\n",
    "\n",
    "    # This forward propagation logic defines the chain propagation of our idea\n",
    "    def forward(self, x):\n",
    "        shared_output = self.shared_layers(x)\n",
    "        task_outputs = []\n",
    "        for i, task_layer in enumerate(self.task_layers):\n",
    "            if i == 0:\n",
    "                task_output = torch.sigmoid(task_layer(shared_output))\n",
    "            else:\n",
    "                task_output = torch.sigmoid(task_layer(shared_output)) * task_outputs[-1]\n",
    "            task_outputs.append(task_output)\n",
    "\n",
    "        return task_outputs# Here I difined the S(x)\n",
    "    \n",
    "    # Modified by Jingyan\n",
    "    def custom_loss(self, task_outputs, targets, masks):\n",
    "        loss = 0\n",
    "        for i, task_output in enumerate(task_outputs):\n",
    "            task_target = targets[i]\n",
    "            task_mask = masks[i]\n",
    "            task_loss = F.binary_cross_entropy(task_output, task_target.float(), reduction='none')\n",
    "            task_loss = task_loss * task_mask.float() # [2048, 1]\n",
    "            # print('task_loss', task_loss.shape)\n",
    "            loss += task_loss.sum() / task_mask.sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:18:12.790110500Z",
     "start_time": "2024-06-15T13:18:12.770109600Z"
    }
   },
   "id": "a3199bbc687f53ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51129e1e324a8b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A few suggestions:\n",
    "\n",
    "- To get better results, I suggest using cross-validation to find the best values for hyperparameters like `lambda_reg`.\n",
    "- It is better to use a learning rate scheduler, early stopping, and model checkpointing to get the best model during the training process.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f537d832d310a347"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training with Gradients as attribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b405e2fb3b9c2eb6"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:11,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Loss: 122.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:01<00:11,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Loss: 79.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:01<00:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Loss: 56.1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:02<00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 3, Average Loss: 40.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:02<00:08,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 4, Average Loss: 30.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(args\u001B[38;5;241m.\u001B[39mepochs):\n\u001B[0;32m     21\u001B[0m     running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (X_train, targets, masks, event_train) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     24\u001B[0m         X_train \u001B[38;5;241m=\u001B[39m X_train\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     25\u001B[0m         X_train\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[1;32mIn[11], line 15\u001B[0m, in \u001B[0;36mMultiTaskDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[idx], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m)], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks))], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent_all[idx]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "def compute_gradients(features, task_output):\n",
    "        inp_grad = grad(outputs=torch.log(task_output),\n",
    "                        inputs=features,\n",
    "                        grad_outputs=torch.ones_like(task_output),\n",
    "                        create_graph=True)[0]\n",
    "        return inp_grad\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "model = MultiTaskModel(in_features, out_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lambda_reg = 0.1\n",
    "\n",
    "\n",
    "for epoch in trange(args.epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X_train, targets, masks, event_train) in enumerate(train_loader):\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        X_train.requires_grad = True\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        masks = [mask.to(device) for mask in masks]\n",
    "        optimizer.zero_grad()\n",
    "        task_outputs = model(X_train)\n",
    "        # Base loss computation\n",
    "        L_base = model.custom_loss(task_outputs, targets, masks)\n",
    "        \n",
    "        Omega_smooth = 0\n",
    "        prev_attributions = None\n",
    "        for t in range(out_features):\n",
    "            current_attributions = compute_gradients(X_train, task_outputs[t])\n",
    "            # Compute smoothing regularization\n",
    "            if prev_attributions is not None:\n",
    "                diff = current_attributions - prev_attributions\n",
    "                Omega_smooth += torch.abs(diff)              \n",
    "            prev_attributions = current_attributions\n",
    "            \n",
    "        # The formula in project description is summation, but I got better result by taking average.\n",
    "        Omega_smooth = torch.sum(Omega_smooth)  # Omega_smooth.mean() #torch.sum(Omega_smooth) \n",
    "        loss = L_base + (lambda_reg * Omega_smooth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'End of Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:18:39.656215600Z",
     "start_time": "2024-06-15T13:18:36.637215900Z"
    }
   },
   "id": "124cc36f6e8d8269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training with Expected Gradients\n",
    "\n",
    "I used the edited package of Expected Gradients by Jingyan, but with a very minor change in the `shap_value` function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baa87568da60a551"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:48,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 0, Average Loss: 16.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:30,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 1, Average Loss: 12.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:04<00:24,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Epoch 2, Average Loss: 9.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:05<00:31,  1.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(args\u001B[38;5;241m.\u001B[39mepochs):\n\u001B[0;32m     19\u001B[0m     running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 20\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (X_train, targets, masks, event_train) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     22\u001B[0m         X_train \u001B[38;5;241m=\u001B[39m X_train\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     23\u001B[0m         X_train\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[1;32mIn[11], line 15\u001B[0m, in \u001B[0;36mMultiTaskDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[idx], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets))], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks))], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent_all[idx]\n",
      "Cell \u001B[1;32mIn[11], line 15\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[idx], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets))], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks[i][idx] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasks))], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent_all[idx]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from expected_gradient_multi_task import AttributionPriorExplainer\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "APExp = AttributionPriorExplainer(train_dataset,args.batch_size)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "model = MultiTaskModel(in_features, out_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lambda_reg = 0.5\n",
    "\n",
    "\n",
    "for epoch in trange(args.epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X_train, targets, masks, event_train) in enumerate(train_loader):\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        X_train.requires_grad = True\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        masks = [mask.to(device) for mask in masks]\n",
    "        optimizer.zero_grad()\n",
    "        task_outputs = model(X_train)\n",
    "        \n",
    "        ## get Expected Gradients attribution\n",
    "        eg = APExp.shap_values(model,X_train)\n",
    "        \n",
    "        # Base loss computation\n",
    "        L_base = model.custom_loss(task_outputs, targets, masks)\n",
    "        \n",
    "        Omega_smooth = 0\n",
    "        prev_attributions = None\n",
    "        for t in range(out_features):\n",
    "            current_attributions = eg[t]\n",
    "            # Compute smoothing regularization\n",
    "            if prev_attributions is not None:\n",
    "                diff = current_attributions - prev_attributions\n",
    "                Omega_smooth += torch.abs(diff)              \n",
    "            prev_attributions = current_attributions\n",
    "            \n",
    "        \n",
    "        Omega_smooth = torch.sum(Omega_smooth)  # Omega_smooth.mean() #torch.sum(Omega_smooth) \n",
    "        loss = L_base + (lambda_reg * Omega_smooth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'End of Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:18:32.912217Z",
     "start_time": "2024-06-15T13:18:26.564463800Z"
    }
   },
   "id": "6c6b61d686a88dad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d601e510c600b62"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Created by Jingyan\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    for X_test, _, _, _ in test_loader:\n",
    "        # Forward pass\n",
    "        X_test = X_test.to(device)\n",
    "        task_outputs_ = model(X_test)\n",
    "\n",
    "        # Store the predictions\n",
    "        test_predictions.append(task_outputs_)\n",
    "test_predictions = [torch.cat([preds[i] for preds in test_predictions]) for i in range(len(test_predictions[0]))]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T12:52:08.684891900Z",
     "start_time": "2024-06-15T12:52:08.621893Z"
    }
   },
   "id": "74496fae689d6c3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Created by Jingyan\n",
    "model.eval()\n",
    "train_predictions = []\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    for X_train, _, _, _ in train_loader:\n",
    "        # Forward pass\n",
    "        X_train = X_train.to(device)\n",
    "        task_outputs_ = model(X_train)\n",
    "\n",
    "        # Store the predictions\n",
    "        train_predictions.append(task_outputs_)\n",
    "\n",
    "# Process the predictions as needed\n",
    "# For example, converting them to a list or concatenating\n",
    "# Here we concatenate the predictions for each task\n",
    "train_predictions = [torch.cat([preds[i] for preds in train_predictions]) for i in range(len(train_predictions[0]))]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T12:52:09.557892900Z",
     "start_time": "2024-06-15T12:52:09.031892200Z"
    }
   },
   "id": "6508055f7f22ff1c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# made by Xinyu\n",
    "def binarize_and_sum_columns(output_list):\n",
    "    def binarize_list(input_list):\n",
    "        tensor = torch.Tensor(input_list)\n",
    "        # print(input_list.max() == input_list.min())\n",
    "        binary_tensor = (tensor >= 0.5).float()\n",
    "        return binary_tensor\n",
    "\n",
    "    result = binarize_list(output_list[0])\n",
    "    for i in range(1, len(output_list)):\n",
    "        binary_column = binarize_list(output_list[i])\n",
    "        # print(binary_column.max() == binary_column.min())\n",
    "        result += binary_column\n",
    "\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T12:52:09.832893500Z",
     "start_time": "2024-06-15T12:52:09.807891800Z"
    }
   },
   "id": "5abcbec3690796dc"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240])\n"
     ]
    }
   ],
   "source": [
    "# made by Xinyu\n",
    "Y_hat_train = binarize_and_sum_columns(train_predictions)\n",
    "Y_hat_train = Y_hat_train.squeeze()\n",
    "print(Y_hat_train.shape)\n",
    "\n",
    "Y_hat_test = binarize_and_sum_columns(test_predictions)\n",
    "Y_hat_test = Y_hat_test.squeeze()\n",
    "# print(Y_hat_test.min(), Y_hat_test.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:09:25.266418500Z",
     "start_time": "2024-06-15T13:09:25.237419800Z"
    }
   },
   "id": "ec4c8e8586cc7642"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "torch.Size([10240, 1])\n",
      "torch.Size([10240])\n",
      "7\n",
      "torch.Size([2048, 1])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# created by Jingyan\n",
    "# Get the true labels and status\n",
    "train_trues = []\n",
    "train_statuses = []\n",
    "for _, train_targets, train_masks, train_status in train_loader:\n",
    "    true_label = [train_targets[i]*train_masks[i] for i in range(len(train_targets))]\n",
    "    train_trues.append(true_label)\n",
    "    train_statuses.append(train_status)\n",
    "train_trues = [torch.cat([preds[i] for preds in train_trues]) for i in range(len(train_trues[0]))]\n",
    "train_statuses = torch.cat([status for status in train_statuses])\n",
    "\n",
    "print(len(train_trues))\n",
    "print(train_trues[0].shape)\n",
    "print(train_statuses.shape)\n",
    "\n",
    "test_trues = []\n",
    "test_statuses = []\n",
    "for _, test_targets, test_masks, test_status in test_loader:\n",
    "    true_label = [test_targets[i]*test_masks[i] for i in range(len(test_targets))]\n",
    "    test_trues.append(true_label)\n",
    "    test_statuses.append(test_status)\n",
    "\n",
    "test_trues = [torch.cat([preds[i] for preds in test_trues]) for i in range(len(test_trues[0]))]\n",
    "test_statuses = torch.cat([status for status in test_statuses])\n",
    "\n",
    "print(len(test_trues))\n",
    "print(test_trues[0].shape)\n",
    "print(test_statuses.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:21:02.721990900Z",
     "start_time": "2024-06-13T21:21:02.121991100Z"
    }
   },
   "id": "cdda5b2e2483f664"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# made by Xinyu\n",
    "Y_true_train = binarize_and_sum_columns(train_trues)\n",
    "Y_true_train = Y_true_train.squeeze()\n",
    "print(Y_true_train.shape)\n",
    "\n",
    "Y_true_test = binarize_and_sum_columns(test_trues)\n",
    "Y_true_test = Y_true_test.squeeze()\n",
    "print(Y_true_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:20:38.245115300Z",
     "start_time": "2024-06-13T21:20:38.228116700Z"
    }
   },
   "id": "4faf8e9a263292cd"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [03:20<00:00, 10.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783050763370184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Cindex(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cindex, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_hat, status):\n",
    "        if not torch.is_tensor(y):\n",
    "            y = torch.Tensor(y)\n",
    "        if not torch.is_tensor(y_hat):\n",
    "            y_hat = torch.Tensor(y_hat)\n",
    "        if not torch.is_tensor(status):\n",
    "          status = torch.Tensor(status)\n",
    "\n",
    "        N = y.size(0)\n",
    "        total_pairs = 0\n",
    "        c = 0\n",
    "\n",
    "        for i in trange(N):\n",
    "            for j in range(i + 1, N):\n",
    "                a = y[i]\n",
    "                b = y[j]\n",
    "                a_hat = y_hat[i]\n",
    "                b_hat = y_hat[j]\n",
    "                astatus = status[i]\n",
    "                bstatus = status[j]\n",
    "                if (a >= b and a_hat >= b_hat and bstatus == 1) or (a <= b and a_hat <= b_hat and astatus == 1):\n",
    "                    c += 1\n",
    "                if (a <= b and astatus==1) or (b <= a and bstatus == 1):\n",
    "                    total_pairs += 1\n",
    "\n",
    "        outcome = c / total_pairs\n",
    "        return outcome\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "# c11_train = cindex_calculator(Y_true_train, Y_hat_train, train_statuses)\n",
    "# print(c11_train)\n",
    "c11_test = cindex_calculator(Y_true_test, Y_hat_test, test_statuses)\n",
    "print(c11_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:28:11.594762200Z",
     "start_time": "2024-06-13T18:24:51.310834700Z"
    }
   },
   "id": "14c1c53eca7b9984"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1b0dd2a019ea70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
