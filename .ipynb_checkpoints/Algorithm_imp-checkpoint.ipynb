{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:18.073562500Z",
     "start_time": "2024-06-13T21:07:17.952562200Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchtuples\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtt\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\__init__.py:562\u001B[0m\n\u001B[0;32m    548\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(textwrap\u001B[38;5;241m.\u001B[39mdedent(\u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;124m            Failed to load PyTorch C extensions:\u001B[39m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;124m                or by running Python from a different directory.\u001B[39m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;124m            \u001B[39m\u001B[38;5;124m'''\u001B[39m)\u001B[38;5;241m.\u001B[39mstrip()) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    560\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m  \u001B[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001B[39;00m\n\u001B[1;32m--> 562\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mdir\u001B[39m(\u001B[43m_C\u001B[49m):\n\u001B[0;32m    563\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m name\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBase\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    564\u001B[0m         __all__\u001B[38;5;241m.\u001B[39mappend(name)\n",
      "\u001B[1;31mNameError\u001B[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import numpy as np\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import numpy as np\n",
    "import easydict\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4d947b03ebf49c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataset/processdata.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin-1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m data \u001B[38;5;241m=\u001B[39m df\n\u001B[0;32m      4\u001B[0m date_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate.of.Last.Contact\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate.of.Diagnostic\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/processdata.csv', encoding='latin-1')\n",
    "data = df\n",
    "\n",
    "date_columns = ['Date.of.Last.Contact', 'Date.of.Diagnostic']\n",
    "data[date_columns] = data[date_columns].apply(pd.to_datetime, errors='coerce')\n",
    "has_na = data[date_columns].isna().any(axis=1)\n",
    "\n",
    "# My comment: why not death time - contact time?\n",
    "if has_na.any():\n",
    "    data['Survival_Time'] = (data['Date.of.Last.Contact'] - data['Date.of.Diagnostic']).dt.days\n",
    "else:\n",
    "    data['Survival_Time'] = (data['Date.of.Last.Contact'] - data['Date.of.Diagnostic']).dt.days\n",
    "    \n",
    "data.loc[:, 'Survival_Time'] = data['Survival_Time'].replace({-1:0})\n",
    "\n",
    "data['indicater'] = np.where(data['Date.of.Death'].isna(), 0, 1)\n",
    "columns_to_drop = ['Date.of.Death', 'Date.of.Last.Contact', 'Date.of.Diagnostic']\n",
    "\n",
    "\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
    "\n",
    "\n",
    "columns_to_one_hot = ['RCBP.Name', 'Raca.Color', 'State.Civil', 'Code.Profession', 'Name.Occupation', 'Status.Address',\n",
    "                      'City.Address', 'Description.of.Topography', 'Topography.Code', 'Morphology.Description',\n",
    "                      'Code.of.Morphology', 'Description.of.Disease', 'Illness.Code', 'Diagnostic.means', 'Extension',\n",
    "                      'Type.of.Death']\n",
    "\n",
    "# Replace other values that are not in top 9, into \"other\"\n",
    "for column in columns_to_one_hot:\n",
    "    top_9_values = data[column].value_counts().nlargest(9).index\n",
    "    data[column] = data[column].where(data[column].isin(top_9_values), 'other')\n",
    "\n",
    "data = pd.get_dummies(data, columns=columns_to_one_hot)\n",
    "\n",
    "columns_to_binarize = ['Gender', 'Indicator.of.Rare.Case']\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "for column in columns_to_binarize:\n",
    "    data[column] = lb.fit_transform(data[column])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['Age'] = scaler.fit_transform(data[['Age']])\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(['Survival_Time', 'indicater'], axis=1)\n",
    "time_all = data['Survival_Time'].values\n",
    "event_all = data['indicater'].values\n",
    "max_time = data['Survival_Time'].max()\n",
    "print(max_time)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:08.655958400Z",
     "start_time": "2024-06-13T21:07:08.605958700Z"
    }
   },
   "id": "6e216450423b1b0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m num_intervals \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m7\u001B[39m\n\u001B[0;32m      7\u001B[0m intervals \u001B[38;5;241m=\u001B[39m [(i \u001B[38;5;241m*\u001B[39m (Tmax \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_intervals), (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m (Tmax \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_intervals)) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_intervals)]\n\u001B[1;32m----> 9\u001B[0m Y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(\u001B[43mtime_all\u001B[49m), num_intervals), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint_)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Until the event happens, value is 1. after that, it is 0\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, time_val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(time_all):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'time_all' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Take the maximum time and divide it into any number of intervals\n",
    "Tmax = 7500\n",
    "num_intervals = 7\n",
    "\n",
    "intervals = [(i * (Tmax // num_intervals), (i + 1) * (Tmax // num_intervals)) for i in range(num_intervals)]\n",
    "\n",
    "Y = np.zeros((len(time_all), num_intervals), dtype=np.int_)\n",
    "\n",
    "# Until the event happens, value is 1. after that, it is 0\n",
    "for i, time_val in enumerate(time_all):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if time_val > right or (left < time_val <= right):\n",
    "            Y[i, j] = 1\n",
    "\n",
    "Y = torch.Tensor(Y)\n",
    "\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:08.827958Z",
     "start_time": "2024-06-13T21:07:08.764958100Z"
    }
   },
   "id": "7982f1558b932fbc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m[data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSurvival_Time\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m1000\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[data['Survival_Time']>1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:08.983958Z",
     "start_time": "2024-06-13T21:07:08.915959300Z"
    }
   },
   "id": "b4428c1ef5bfb4e4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindicater\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['indicater'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:09.077958900Z",
     "start_time": "2024-06-13T21:07:09.048959200Z"
    }
   },
   "id": "f70b57a214ec3f87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[data['indicater']==0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbd1cdbd6158e093"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Creat mask matrix\n",
    "W = np.zeros((len(time_all), num_intervals), dtype=np.int_)\n",
    "\n",
    "# Until the time we know he was alive the value is 1, after that is 0\n",
    "for i, (time_val, event_val) in enumerate(zip(time_all, event_all)):\n",
    "    for j, (left, right) in enumerate(intervals):\n",
    "        if event_val == 0 and time_val < left:\n",
    "            W[i, j] = 0\n",
    "        else:\n",
    "            W[i, j] = 1\n",
    "\n",
    "W = torch.Tensor(W)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:35:37.436763300Z",
     "start_time": "2024-06-13T15:35:37.398765Z"
    }
   },
   "id": "aee8a942a43ad246"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1., 1., 0., 0., 0.])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[4]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:41:11.194656200Z",
     "start_time": "2024-06-13T15:41:11.171650700Z"
    }
   },
   "id": "e3f3fe0b47e5b44d"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# change the batch size from 1024 to 3222 to improve the performance\n",
    "# created by Xinyu modified by Jingyan\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 2048,\n",
    "    \"cuda\": True, # should set it to be true when using gpu, otherwise data would be on two devices\n",
    "    \"lr\": 0.05,\n",
    "    \"seed\": 1111,\n",
    "    \"reduce_rate\": 0.95,\n",
    "    \"epochs\": 20,\n",
    "    \"clip\": 5.0,\n",
    "    \"log_interval\":10,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T17:45:22.848113200Z",
     "start_time": "2024-06-13T17:45:22.808113500Z"
    }
   },
   "id": "4dea0085b9de1032"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14755, 138])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].dtype == bool:\n",
    "        X[col] = X[col].astype(int)\n",
    "X_use = torch.tensor(X.values, dtype=torch.float32)\n",
    "X_use.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:42:57.464103400Z",
     "start_time": "2024-06-13T15:42:57.420103800Z"
    }
   },
   "id": "e044d45dbc19fff8"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14755, 1])\n",
      "torch.Size([14755, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert n*m data into m * n * 1 \n",
    "Y_transform = [Y[:, i:i+1] for i in range(Y.size(1))]\n",
    "print(Y_transform[0].shape)\n",
    "W_transform = [W[:, i:i+1] for i in range(W.size(1))]\n",
    "print(W_transform[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:43:31.200611500Z",
     "start_time": "2024-06-13T15:43:31.180614Z"
    }
   },
   "id": "7fb75f8a97c41835"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Jingyan adds the dataloader\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, data, targets, masks, event_all):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.masks = masks\n",
    "        self.event_all = event_all\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], [self.targets[i][idx] for i in range(len(self.targets))], [self.masks[i][idx] for i in range(len(self.masks))], self.event_all[idx]\n",
    "\n",
    "\n",
    "#Xinyu\n",
    "full_dataset = MultiTaskDataset(X_use, Y_transform, W_transform, event_all)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:44:35.035462100Z",
     "start_time": "2024-06-13T15:44:35.015462200Z"
    }
   },
   "id": "2c560d3656abe8b8"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 138])\n",
      "7 torch.Size([2048, 1])\n",
      "7 torch.Size([2048, 1])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "for x, y, w, e in train_loader:\n",
    "    print(x.shape)\n",
    "    print(len(y), y[0].shape)\n",
    "    print(len(w), w[0].shape)\n",
    "    print(e.shape)\n",
    "    in_features = x.shape[1]\n",
    "    out_features = len(y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T15:46:00.903037100Z",
     "start_time": "2024-06-13T15:46:00.826036400Z"
    }
   },
   "id": "ef00714e2ad3279b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d65fa65c857213"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Made by Xinyu and modified by Dr.Li and Jingyan\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.num_tasks = out_features\n",
    "        self.input_features = in_features\n",
    "\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.AlphaDropout(0.1)\n",
    "        )\n",
    "        # A Classic Multi Task Learning Framework\n",
    "        self.task_layers = nn.ModuleList([nn.Linear(128, 1) for _ in range(out_features)])#after your papaer I decided to use MTL to solve this prob\n",
    "\n",
    "    # This forward propagation logic defines the chain propagation of our idea\n",
    "    def forward(self, x):\n",
    "        shared_output = self.shared_layers(x)\n",
    "        task_outputs = []\n",
    "        for i, task_layer in enumerate(self.task_layers):\n",
    "            if i == 0:\n",
    "                task_output = torch.sigmoid(task_layer(shared_output))\n",
    "            else:\n",
    "                task_output = torch.sigmoid(task_layer(shared_output)) * task_outputs[-1]\n",
    "            task_outputs.append(task_output)\n",
    "\n",
    "        return task_outputs# Here I difined the S(x)\n",
    "    \n",
    "    # Modified by Jingyan\n",
    "    def custom_loss(self, task_outputs, targets, masks):\n",
    "        loss = 0\n",
    "        for i, task_output in enumerate(task_outputs):\n",
    "            task_target = targets[i]\n",
    "            task_mask = masks[i]\n",
    "            task_loss = F.binary_cross_entropy(task_output, task_target.float(), reduction='none')\n",
    "            task_loss = task_loss * task_mask.float() # [2048, 1]\n",
    "            # print('task_loss', task_loss.shape)\n",
    "            loss += task_loss.sum() / task_mask.sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:38:17.424536Z",
     "start_time": "2024-06-13T18:38:17.399536900Z"
    }
   },
   "id": "a3199bbc687f53ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51129e1e324a8b2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm, trange\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m grad\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlr_scheduler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ReduceLROnPlateau\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_gradients\u001B[39m(features, task_output):\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;66;03m# features.requires_grad = True\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\__init__.py:1539\u001B[0m\n\u001B[0;32m   1532\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compile\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _disable_dynamo\n\u001B[0;32m   1534\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[0;32m   1535\u001B[0m \u001B[38;5;66;03m# Import interface functions defined in Python\u001B[39;00m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \n\u001B[0;32m   1538\u001B[0m \u001B[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001B[39;00m\n\u001B[1;32m-> 1539\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m   1542\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;66;03m# Remove unnecessary members\u001B[39;00m\n\u001B[0;32m   1544\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _StorageBase\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\functional.py:9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _add_docstr\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lowrank\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m svd_lowrank, pca_lowrank\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moverrides\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001B[0;32m     13\u001B[0m     handle_torch_function)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\nn\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparameter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     Parameter \u001B[38;5;28;01mas\u001B[39;00m Parameter,\n\u001B[0;32m      4\u001B[0m     UninitializedParameter \u001B[38;5;28;01mas\u001B[39;00m UninitializedParameter,\n\u001B[0;32m      5\u001B[0m     UninitializedBuffer \u001B[38;5;28;01mas\u001B[39;00m UninitializedBuffer,\n\u001B[0;32m      6\u001B[0m )\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataParallel \u001B[38;5;28;01mas\u001B[39;00m DataParallel\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\nn\\modules\\__init__.py:28\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpadding\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad1d, ReplicationPad2d, \\\n\u001B[0;32m     25\u001B[0m     ReplicationPad3d, ZeroPad1d, ZeroPad2d, ZeroPad3d, ConstantPad1d, ConstantPad2d, ConstantPad3d, \\\n\u001B[0;32m     26\u001B[0m     CircularPad1d, CircularPad2d, CircularPad3d\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Embedding, EmbeddingBag\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RNNBase, RNN, LSTM, GRU, \\\n\u001B[0;32m     29\u001B[0m     RNNCellBase, RNNCell, LSTMCell, GRUCell\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpixelshuffle\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PixelShuffle, PixelUnshuffle\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mupsampling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UpsamplingNearest2d, UpsamplingBilinear2d, Upsample\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\future\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparameter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Parameter\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PackedSequence\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m init\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _VF\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1006\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:688\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:879\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:975\u001B[0m, in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1074\u001B[0m, in \u001B[0;36mget_data\u001B[1;34m(self, path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "def compute_gradients(features, task_output):\n",
    "        # features.requires_grad = True\n",
    "        inp_grad = grad(outputs=task_output,\n",
    "                        inputs=features,\n",
    "                        grad_outputs=torch.ones_like(task_output),\n",
    "                        create_graph=True)[0]\n",
    "        # features.requires_grad = False\n",
    "        mg = inp_grad.abs().mean(0) # 138\n",
    "        return inp_grad\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "model = MultiTaskModel(in_features, out_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lambda_reg = 0.5\n",
    "\n",
    "\n",
    "for epoch in trange(10):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X_train, targets, masks, event_train) in enumerate(train_loader):\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        X_train.requires_grad = True\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        masks = [mask.to(device) for mask in masks]\n",
    "        optimizer.zero_grad()\n",
    "        task_outputs = model(X_train)\n",
    "        # Base loss computation\n",
    "        L_base = model.custom_loss(task_outputs, targets, masks)\n",
    "        \n",
    "        Omega_smooth = 0\n",
    "        Rsmooth = 0\n",
    "        prev_attributions = None\n",
    "        for t in range(out_features):\n",
    "            current_attributions = compute_gradients(X_train, task_outputs[t])\n",
    "            # Compute smoothing regularization\n",
    "            if prev_attributions is not None:\n",
    "                diff = current_attributions - prev_attributions\n",
    "                norm_diff = torch.norm(diff, p=1)\n",
    "                Rsmooth += norm_diff\n",
    "                Omega_smooth += torch.abs(diff)              \n",
    "            prev_attributions = current_attributions\n",
    "            \n",
    "        # The formula in project description is summation, but I got better result by taking average.\n",
    "        Omega_smooth = torch.sum(Omega_smooth)  # Omega_smooth.mean() #torch.sum(Omega_smooth) \n",
    "        print(Omega_smooth,',', Rsmooth)\n",
    "        loss = L_base + (lambda_reg * Omega_smooth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'End of Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:07:05.509285600Z",
     "start_time": "2024-06-13T21:07:03.722268300Z"
    }
   },
   "id": "124cc36f6e8d8269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d601e510c600b62"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "# Created by Jingyan\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    for X_test, _, _, _ in test_loader:\n",
    "        # Forward pass\n",
    "        X_test = X_test.to(device)\n",
    "        task_outputs_ = model(X_test)\n",
    "\n",
    "        # Store the predictions\n",
    "        test_predictions.append(task_outputs_)\n",
    "test_predictions = [torch.cat([preds[i] for preds in test_predictions]) for i in range(len(test_predictions[0]))]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:48.468325700Z",
     "start_time": "2024-06-13T18:24:48.295325400Z"
    }
   },
   "id": "74496fae689d6c3"
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "# Created by Jingyan\n",
    "model.eval()\n",
    "train_predictions = []\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    for X_train, _, _, _ in train_loader:\n",
    "        # Forward pass\n",
    "        X_train = X_train.to(device)\n",
    "        task_outputs_ = model(X_train)\n",
    "\n",
    "        # Store the predictions\n",
    "        train_predictions.append(task_outputs_)\n",
    "\n",
    "# Process the predictions as needed\n",
    "# For example, converting them to a list or concatenating\n",
    "# Here we concatenate the predictions for each task\n",
    "train_predictions = [torch.cat([preds[i] for preds in train_predictions]) for i in range(len(train_predictions[0]))]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:48.906326100Z",
     "start_time": "2024-06-13T18:24:48.467325900Z"
    }
   },
   "id": "6508055f7f22ff1c"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# made by Xinyu\n",
    "def binarize_and_sum_columns(output_list):\n",
    "    def binarize_list(input_list):\n",
    "        tensor = torch.Tensor(input_list)\n",
    "        # print(input_list.max() == input_list.min())\n",
    "        binary_tensor = (tensor >= 0.5).float()\n",
    "        return binary_tensor\n",
    "\n",
    "    result = binarize_list(output_list[0])\n",
    "    for i in range(1, len(output_list)):\n",
    "        binary_column = binarize_list(output_list[i])\n",
    "        # print(binary_column.max() == binary_column.min())\n",
    "        result += binary_column\n",
    "\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:48.908326800Z",
     "start_time": "2024-06-13T18:24:48.894327Z"
    }
   },
   "id": "5abcbec3690796dc"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240])\n",
      "tensor(0., device='cuda:0') tensor(7., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# made by Xinyu\n",
    "Y_hat_train = binarize_and_sum_columns(train_predictions)\n",
    "Y_hat_train = Y_hat_train.squeeze()\n",
    "print(Y_hat_train.shape)\n",
    "\n",
    "Y_hat_test = binarize_and_sum_columns(test_predictions)\n",
    "Y_hat_test = Y_hat_test.squeeze()\n",
    "print(Y_hat_test.min(), Y_hat_test.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:48.925326Z",
     "start_time": "2024-06-13T18:24:48.908326800Z"
    }
   },
   "id": "ec4c8e8586cc7642"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "torch.Size([10240, 1])\n",
      "torch.Size([10240])\n",
      "7\n",
      "torch.Size([2048, 1])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# created by Jingyan\n",
    "# Get the true labels and status\n",
    "train_trues = []\n",
    "train_statuses = []\n",
    "for _, train_targets, train_masks, train_status in train_loader:\n",
    "    true_label = [train_targets[i]*train_masks[i] for i in range(len(train_targets))]\n",
    "    train_trues.append(true_label)\n",
    "    train_statuses.append(train_status)\n",
    "train_trues = [torch.cat([preds[i] for preds in train_trues]) for i in range(len(train_trues[0]))]\n",
    "train_statuses = torch.cat([status for status in train_statuses])\n",
    "\n",
    "print(len(train_trues))\n",
    "print(train_trues[0].shape)\n",
    "print(train_statuses.shape)\n",
    "\n",
    "test_trues = []\n",
    "test_statuses = []\n",
    "for _, test_targets, test_masks, test_status in test_loader:\n",
    "    true_label = [test_targets[i]*test_masks[i] for i in range(len(test_targets))]\n",
    "    test_trues.append(true_label)\n",
    "    test_statuses.append(test_status)\n",
    "\n",
    "test_trues = [torch.cat([preds[i] for preds in test_trues]) for i in range(len(test_trues[0]))]\n",
    "test_statuses = torch.cat([status for status in test_statuses])\n",
    "\n",
    "print(len(test_trues))\n",
    "print(test_trues[0].shape)\n",
    "print(test_statuses.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:50.894325900Z",
     "start_time": "2024-06-13T18:24:50.265325900Z"
    }
   },
   "id": "cdda5b2e2483f664"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240])\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# made by Xinyu\n",
    "Y_true_train = binarize_and_sum_columns(train_trues)\n",
    "Y_true_train = Y_true_train.squeeze()\n",
    "print(Y_true_train.shape)\n",
    "\n",
    "Y_true_test = binarize_and_sum_columns(test_trues)\n",
    "Y_true_test = Y_true_test.squeeze()\n",
    "print(Y_true_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:24:50.926325400Z",
     "start_time": "2024-06-13T18:24:50.882325400Z"
    }
   },
   "id": "4faf8e9a263292cd"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [03:20<00:00, 10.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783050763370184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Cindex(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cindex, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_hat, status):\n",
    "        if not torch.is_tensor(y):\n",
    "            y = torch.Tensor(y)\n",
    "        if not torch.is_tensor(y_hat):\n",
    "            y_hat = torch.Tensor(y_hat)\n",
    "        if not torch.is_tensor(status):\n",
    "          status = torch.Tensor(status)\n",
    "\n",
    "        N = y.size(0)\n",
    "        total_pairs = 0\n",
    "        c = 0\n",
    "\n",
    "        for i in trange(N):\n",
    "            for j in range(i + 1, N):\n",
    "                a = y[i]\n",
    "                b = y[j]\n",
    "                a_hat = y_hat[i]\n",
    "                b_hat = y_hat[j]\n",
    "                astatus = status[i]\n",
    "                bstatus = status[j]\n",
    "                if (a >= b and a_hat >= b_hat and bstatus == 1) or (a <= b and a_hat <= b_hat and astatus == 1):\n",
    "                    c += 1\n",
    "                if (a <= b and astatus==1) or (b <= a and bstatus == 1):\n",
    "                    total_pairs += 1\n",
    "\n",
    "        outcome = c / total_pairs\n",
    "        return outcome\n",
    "\n",
    "cindex_calculator = Cindex()\n",
    "# c11_train = cindex_calculator(Y_true_train, Y_hat_train, train_statuses)\n",
    "# print(c11_train)\n",
    "c11_test = cindex_calculator(Y_true_test, Y_hat_test, test_statuses)\n",
    "print(c11_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T18:28:11.594762200Z",
     "start_time": "2024-06-13T18:24:51.310834700Z"
    }
   },
   "id": "14c1c53eca7b9984"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1b0dd2a019ea70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
